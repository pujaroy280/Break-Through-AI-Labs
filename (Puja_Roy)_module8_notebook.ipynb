{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "python_kernel",
      "language": "python",
      "name": "python_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "(Puja Roy) module8.notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63118e0e"
      },
      "source": [
        "# Lab 8 - Deep Learning 3"
      ],
      "id": "63118e0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6deb3d5"
      },
      "source": [
        "The goal of this week's lab is to learn to use another widely-used neural network module: recurrent neural networks (RNNs). We can use it to learn features from sequences such as time series and text."
      ],
      "id": "b6deb3d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dbf2af7"
      },
      "source": [
        "![image](https://www.researchgate.net/profile/Huy-Tien-Nguyen/publication/321259272/figure/fig2/AS:572716866433034@1513557749934/Illustration-of-our-LSTM-model-for-sentiment-classification-Each-word-is-transfered-to-a_W640.jpg)"
      ],
      "id": "0dbf2af7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de11e2a9"
      },
      "source": [
        "How should we extract features from sequences, which might be of variable length? Recurrent Neural Networks (RNNs) provide a solution by summarizing the entire sequence into a fixed-size vector representation. This week we will walk through how to use RNNs for sequence processing."
      ],
      "id": "de11e2a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3636875d"
      },
      "source": [
        "* **Review**: Convolutional Neural Networks (CNNs)\n",
        "* **Unit A**: Time Series Classification and Recurrent Neural Networks (RNNs)\n",
        "* **Unit B**: Recurrent Neural Networks for Text Classification"
      ],
      "id": "3636875d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "814ad1ce"
      },
      "source": [
        "## Review"
      ],
      "id": "814ad1ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15a9a0fe"
      },
      "source": [
        "Last time we learned the basics of convolutional neural networks (CNNs) and used them for image classification."
      ],
      "id": "15a9a0fe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:05:57.924793Z",
          "iopub.status.busy": "2021-08-05T17:05:57.923890Z",
          "iopub.status.idle": "2021-08-05T17:06:05.571919Z",
          "shell.execute_reply": "2021-08-05T17:06:05.572969Z"
        },
        "id": "0e29fe7f"
      },
      "source": [
        "# For Tables\n",
        "import pandas as pd\n",
        "# For Visualization\n",
        "import altair as alt\n",
        "# For Scikit-Learn\n",
        "import sklearn\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# For Neural Networks\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape"
      ],
      "id": "0e29fe7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dd8dd03"
      },
      "source": [
        "We will also turn off warnings."
      ],
      "id": "3dd8dd03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:05.579148Z",
          "iopub.status.busy": "2021-08-05T17:06:05.578323Z",
          "iopub.status.idle": "2021-08-05T17:06:05.580599Z",
          "shell.execute_reply": "2021-08-05T17:06:05.581066Z"
        },
        "id": "375ed265"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "375ed265",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f03c95b6"
      },
      "source": [
        "We saw in last week how to store images and their labels in Pandas dataframes."
      ],
      "id": "f03c95b6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:05.587309Z",
          "iopub.status.busy": "2021-08-05T17:06:05.586183Z",
          "iopub.status.idle": "2021-08-05T17:06:23.270341Z",
          "shell.execute_reply": "2021-08-05T17:06:23.271646Z"
        },
        "id": "53a619e2"
      },
      "source": [
        "df_train = pd.read_csv('https://srush.github.io/BT-AI/notebooks/mnist_train.csv.gz', compression='gzip')\n",
        "df_test = pd.read_csv('https://srush.github.io/BT-AI/notebooks/mnist_test.csv.gz', compression='gzip')"
      ],
      "id": "53a619e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21c9aa96"
      },
      "source": [
        "The column `class` stores the class of each image, which is a number between 0 and 9."
      ],
      "id": "21c9aa96"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:23.303053Z",
          "iopub.status.busy": "2021-08-05T17:06:23.301474Z",
          "iopub.status.idle": "2021-08-05T17:06:23.367500Z",
          "shell.execute_reply": "2021-08-05T17:06:23.368078Z"
        },
        "id": "2d90cbe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda746fe-748e-4537-ebb7-cdd69fb37b5a"
      },
      "source": [
        "df_train[:100][\"class\"].unique()"
      ],
      "id": "2d90cbe9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 3, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d33e444a"
      },
      "source": [
        "The rest of columns store the features, where we have 784 features since our images are 28x28. Each feature stores the intensity at each pixel : for instance, the column \"3x4\" stores the pixel value at the 3rd row and the 4th column. Since the size of each image is 28x28, there are 28 rows and 28 columns."
      ],
      "id": "d33e444a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369e49f2"
      },
      "source": [
        "To make later processing easier, we store the names of pixel value columns in a list `features`."
      ],
      "id": "369e49f2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:23.377237Z",
          "iopub.status.busy": "2021-08-05T17:06:23.376283Z",
          "iopub.status.idle": "2021-08-05T17:06:23.379635Z",
          "shell.execute_reply": "2021-08-05T17:06:23.380165Z"
        },
        "id": "0ca90f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a6ca7f-3c66-4ae5-a634-5af5f2eaf21e"
      },
      "source": [
        "features = []\n",
        "for i in range(1, 29):\n",
        "    for j in range(1, 29):\n",
        "        features.append(str(i) + \"x\" + str(j))\n",
        "len(features)"
      ],
      "id": "0ca90f8a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2c5bb92"
      },
      "source": [
        "We used the below utility functions for visualizing the images."
      ],
      "id": "d2c5bb92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9e07eff"
      },
      "source": [
        "Convert feature to x, y, and value."
      ],
      "id": "f9e07eff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:23.393744Z",
          "iopub.status.busy": "2021-08-05T17:06:23.391118Z",
          "iopub.status.idle": "2021-08-05T17:06:23.394684Z",
          "shell.execute_reply": "2021-08-05T17:06:23.395221Z"
        },
        "lines_to_next_cell": 1,
        "id": "21e2fe5e"
      },
      "source": [
        "def position(row):\n",
        "    y, x = row[\"index\"].split(\"x\")\n",
        "    return {\"x\":int(x),\n",
        "            \"y\":int(y),\n",
        "            \"val\":row[\"val\"]}\n",
        "def draw_image(i, shuffle=False):\n",
        "    t = df_train[i:i+1].T.reset_index().rename(columns={i: \"val\"})\n",
        "    out = t.loc[t[\"index\"] != \"class\"].apply(position, axis=1, result_type=\"expand\")\n",
        "\n",
        "    label = df_train.loc[i][\"class\"]\n",
        "    title = \"Image of a \" + str(label)\n",
        "    if shuffle:\n",
        "        out[\"val\"] = sklearn.utils.shuffle(out[\"val\"], random_state=1234).reset_index()[\"val\"]\n",
        "        title = \"Shuffled Image of a \" + str(label)\n",
        "        \n",
        "    return (alt.Chart(out)\n",
        "            .mark_rect()\n",
        "            .properties(title=title)\n",
        "            .encode(\n",
        "                x=\"x:O\",\n",
        "                y=\"y:O\",\n",
        "                fill=\"val:Q\",\n",
        "                color=\"val:Q\",\n",
        "                tooltip=(\"x\", \"y\", \"val\")\n",
        "            ))"
      ],
      "id": "21e2fe5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f107b71"
      },
      "source": [
        "We can visualize an example image."
      ],
      "id": "1f107b71"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:23.401820Z",
          "iopub.status.busy": "2021-08-05T17:06:23.400735Z",
          "iopub.status.idle": "2021-08-05T17:06:24.215624Z",
          "shell.execute_reply": "2021-08-05T17:06:24.216205Z"
        },
        "lines_to_next_cell": 1,
        "id": "4095179a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "f2a52f5c-635e-435d-efb6-45aebbd2c853"
      },
      "source": [
        "im = draw_image(0)\n",
        "im"
      ],
      "id": "4095179a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-68e4c55d3ccd4218b73f89cef4d450af\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-68e4c55d3ccd4218b73f89cef4d450af\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-68e4c55d3ccd4218b73f89cef4d450af\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9c050b0a06c628e9c182165982d596c4\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"val\"}, \"fill\": {\"type\": \"quantitative\", \"field\": \"val\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"x\"}, {\"type\": \"quantitative\", \"field\": \"y\"}, {\"type\": \"quantitative\", \"field\": \"val\"}], \"x\": {\"type\": \"ordinal\", \"field\": \"x\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"y\"}}, \"title\": \"Image of a 5\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-9c050b0a06c628e9c182165982d596c4\": [{\"x\": 1, \"y\": 1, \"val\": 0}, {\"x\": 2, \"y\": 1, \"val\": 0}, {\"x\": 3, \"y\": 1, \"val\": 0}, {\"x\": 4, \"y\": 1, \"val\": 0}, {\"x\": 5, \"y\": 1, \"val\": 0}, {\"x\": 6, \"y\": 1, \"val\": 0}, {\"x\": 7, \"y\": 1, \"val\": 0}, {\"x\": 8, \"y\": 1, \"val\": 0}, {\"x\": 9, \"y\": 1, \"val\": 0}, {\"x\": 10, \"y\": 1, \"val\": 0}, {\"x\": 11, \"y\": 1, \"val\": 0}, {\"x\": 12, \"y\": 1, \"val\": 0}, {\"x\": 13, \"y\": 1, \"val\": 0}, {\"x\": 14, \"y\": 1, \"val\": 0}, {\"x\": 15, \"y\": 1, \"val\": 0}, {\"x\": 16, \"y\": 1, \"val\": 0}, {\"x\": 17, \"y\": 1, \"val\": 0}, {\"x\": 18, \"y\": 1, \"val\": 0}, {\"x\": 19, \"y\": 1, \"val\": 0}, {\"x\": 20, \"y\": 1, \"val\": 0}, {\"x\": 21, \"y\": 1, \"val\": 0}, {\"x\": 22, \"y\": 1, \"val\": 0}, {\"x\": 23, \"y\": 1, \"val\": 0}, {\"x\": 24, \"y\": 1, \"val\": 0}, {\"x\": 25, \"y\": 1, \"val\": 0}, {\"x\": 26, \"y\": 1, \"val\": 0}, {\"x\": 27, \"y\": 1, \"val\": 0}, {\"x\": 28, \"y\": 1, \"val\": 0}, {\"x\": 1, \"y\": 2, \"val\": 0}, {\"x\": 2, \"y\": 2, \"val\": 0}, {\"x\": 3, \"y\": 2, \"val\": 0}, {\"x\": 4, \"y\": 2, \"val\": 0}, {\"x\": 5, \"y\": 2, \"val\": 0}, {\"x\": 6, \"y\": 2, \"val\": 0}, {\"x\": 7, \"y\": 2, \"val\": 0}, {\"x\": 8, \"y\": 2, \"val\": 0}, {\"x\": 9, \"y\": 2, \"val\": 0}, {\"x\": 10, \"y\": 2, \"val\": 0}, {\"x\": 11, \"y\": 2, \"val\": 0}, {\"x\": 12, \"y\": 2, \"val\": 0}, {\"x\": 13, \"y\": 2, \"val\": 0}, {\"x\": 14, \"y\": 2, \"val\": 0}, {\"x\": 15, \"y\": 2, \"val\": 0}, {\"x\": 16, \"y\": 2, \"val\": 0}, {\"x\": 17, \"y\": 2, \"val\": 0}, {\"x\": 18, \"y\": 2, \"val\": 0}, {\"x\": 19, \"y\": 2, \"val\": 0}, {\"x\": 20, \"y\": 2, \"val\": 0}, {\"x\": 21, \"y\": 2, \"val\": 0}, {\"x\": 22, \"y\": 2, \"val\": 0}, {\"x\": 23, \"y\": 2, \"val\": 0}, {\"x\": 24, \"y\": 2, \"val\": 0}, {\"x\": 25, \"y\": 2, \"val\": 0}, {\"x\": 26, \"y\": 2, \"val\": 0}, {\"x\": 27, \"y\": 2, \"val\": 0}, {\"x\": 28, \"y\": 2, \"val\": 0}, {\"x\": 1, \"y\": 3, \"val\": 0}, {\"x\": 2, \"y\": 3, \"val\": 0}, {\"x\": 3, \"y\": 3, \"val\": 0}, {\"x\": 4, \"y\": 3, \"val\": 0}, {\"x\": 5, \"y\": 3, \"val\": 0}, {\"x\": 6, \"y\": 3, \"val\": 0}, {\"x\": 7, \"y\": 3, \"val\": 0}, {\"x\": 8, \"y\": 3, \"val\": 0}, {\"x\": 9, \"y\": 3, \"val\": 0}, {\"x\": 10, \"y\": 3, \"val\": 0}, {\"x\": 11, \"y\": 3, \"val\": 0}, {\"x\": 12, \"y\": 3, \"val\": 0}, {\"x\": 13, \"y\": 3, \"val\": 0}, {\"x\": 14, \"y\": 3, \"val\": 0}, {\"x\": 15, \"y\": 3, \"val\": 0}, {\"x\": 16, \"y\": 3, \"val\": 0}, {\"x\": 17, \"y\": 3, \"val\": 0}, {\"x\": 18, \"y\": 3, \"val\": 0}, {\"x\": 19, \"y\": 3, \"val\": 0}, {\"x\": 20, \"y\": 3, \"val\": 0}, {\"x\": 21, \"y\": 3, \"val\": 0}, {\"x\": 22, \"y\": 3, \"val\": 0}, {\"x\": 23, \"y\": 3, \"val\": 0}, {\"x\": 24, \"y\": 3, \"val\": 0}, {\"x\": 25, \"y\": 3, \"val\": 0}, {\"x\": 26, \"y\": 3, \"val\": 0}, {\"x\": 27, \"y\": 3, \"val\": 0}, {\"x\": 28, \"y\": 3, \"val\": 0}, {\"x\": 1, \"y\": 4, \"val\": 0}, {\"x\": 2, \"y\": 4, \"val\": 0}, {\"x\": 3, \"y\": 4, \"val\": 0}, {\"x\": 4, \"y\": 4, \"val\": 0}, {\"x\": 5, \"y\": 4, \"val\": 0}, {\"x\": 6, \"y\": 4, \"val\": 0}, {\"x\": 7, \"y\": 4, \"val\": 0}, {\"x\": 8, \"y\": 4, \"val\": 0}, {\"x\": 9, \"y\": 4, \"val\": 0}, {\"x\": 10, \"y\": 4, \"val\": 0}, {\"x\": 11, \"y\": 4, \"val\": 0}, {\"x\": 12, \"y\": 4, \"val\": 0}, {\"x\": 13, \"y\": 4, \"val\": 0}, {\"x\": 14, \"y\": 4, \"val\": 0}, {\"x\": 15, \"y\": 4, \"val\": 0}, {\"x\": 16, \"y\": 4, \"val\": 0}, {\"x\": 17, \"y\": 4, \"val\": 0}, {\"x\": 18, \"y\": 4, \"val\": 0}, {\"x\": 19, \"y\": 4, \"val\": 0}, {\"x\": 20, \"y\": 4, \"val\": 0}, {\"x\": 21, \"y\": 4, \"val\": 0}, {\"x\": 22, \"y\": 4, \"val\": 0}, {\"x\": 23, \"y\": 4, \"val\": 0}, {\"x\": 24, \"y\": 4, \"val\": 0}, {\"x\": 25, \"y\": 4, \"val\": 0}, {\"x\": 26, \"y\": 4, \"val\": 0}, {\"x\": 27, \"y\": 4, \"val\": 0}, {\"x\": 28, \"y\": 4, \"val\": 0}, {\"x\": 1, \"y\": 5, \"val\": 0}, {\"x\": 2, \"y\": 5, \"val\": 0}, {\"x\": 3, \"y\": 5, \"val\": 0}, {\"x\": 4, \"y\": 5, \"val\": 0}, {\"x\": 5, \"y\": 5, \"val\": 0}, {\"x\": 6, \"y\": 5, \"val\": 0}, {\"x\": 7, \"y\": 5, \"val\": 0}, {\"x\": 8, \"y\": 5, \"val\": 0}, {\"x\": 9, \"y\": 5, \"val\": 0}, {\"x\": 10, \"y\": 5, \"val\": 0}, {\"x\": 11, \"y\": 5, \"val\": 0}, {\"x\": 12, \"y\": 5, \"val\": 0}, {\"x\": 13, \"y\": 5, \"val\": 0}, {\"x\": 14, \"y\": 5, \"val\": 0}, {\"x\": 15, \"y\": 5, \"val\": 0}, {\"x\": 16, \"y\": 5, \"val\": 0}, {\"x\": 17, \"y\": 5, \"val\": 0}, {\"x\": 18, \"y\": 5, \"val\": 0}, {\"x\": 19, \"y\": 5, \"val\": 0}, {\"x\": 20, \"y\": 5, \"val\": 0}, {\"x\": 21, \"y\": 5, \"val\": 0}, {\"x\": 22, \"y\": 5, \"val\": 0}, {\"x\": 23, \"y\": 5, \"val\": 0}, {\"x\": 24, \"y\": 5, \"val\": 0}, {\"x\": 25, \"y\": 5, \"val\": 0}, {\"x\": 26, \"y\": 5, \"val\": 0}, {\"x\": 27, \"y\": 5, \"val\": 0}, {\"x\": 28, \"y\": 5, \"val\": 0}, {\"x\": 1, \"y\": 6, \"val\": 0}, {\"x\": 2, \"y\": 6, \"val\": 0}, {\"x\": 3, \"y\": 6, \"val\": 0}, {\"x\": 4, \"y\": 6, \"val\": 0}, {\"x\": 5, \"y\": 6, \"val\": 0}, {\"x\": 6, \"y\": 6, \"val\": 0}, {\"x\": 7, \"y\": 6, \"val\": 0}, {\"x\": 8, \"y\": 6, \"val\": 0}, {\"x\": 9, \"y\": 6, \"val\": 0}, {\"x\": 10, \"y\": 6, \"val\": 0}, {\"x\": 11, \"y\": 6, \"val\": 0}, {\"x\": 12, \"y\": 6, \"val\": 0}, {\"x\": 13, \"y\": 6, \"val\": 3}, {\"x\": 14, \"y\": 6, \"val\": 18}, {\"x\": 15, \"y\": 6, \"val\": 18}, {\"x\": 16, \"y\": 6, \"val\": 18}, {\"x\": 17, \"y\": 6, \"val\": 126}, {\"x\": 18, \"y\": 6, \"val\": 136}, {\"x\": 19, \"y\": 6, \"val\": 175}, {\"x\": 20, \"y\": 6, \"val\": 26}, {\"x\": 21, \"y\": 6, \"val\": 166}, {\"x\": 22, \"y\": 6, \"val\": 255}, {\"x\": 23, \"y\": 6, \"val\": 247}, {\"x\": 24, \"y\": 6, \"val\": 127}, {\"x\": 25, \"y\": 6, \"val\": 0}, {\"x\": 26, \"y\": 6, \"val\": 0}, {\"x\": 27, \"y\": 6, \"val\": 0}, {\"x\": 28, \"y\": 6, \"val\": 0}, {\"x\": 1, \"y\": 7, \"val\": 0}, {\"x\": 2, \"y\": 7, \"val\": 0}, {\"x\": 3, \"y\": 7, \"val\": 0}, {\"x\": 4, \"y\": 7, \"val\": 0}, {\"x\": 5, \"y\": 7, \"val\": 0}, {\"x\": 6, \"y\": 7, \"val\": 0}, {\"x\": 7, \"y\": 7, \"val\": 0}, {\"x\": 8, \"y\": 7, \"val\": 0}, {\"x\": 9, \"y\": 7, \"val\": 30}, {\"x\": 10, \"y\": 7, \"val\": 36}, {\"x\": 11, \"y\": 7, \"val\": 94}, {\"x\": 12, \"y\": 7, \"val\": 154}, {\"x\": 13, \"y\": 7, \"val\": 170}, {\"x\": 14, \"y\": 7, \"val\": 253}, {\"x\": 15, \"y\": 7, \"val\": 253}, {\"x\": 16, \"y\": 7, \"val\": 253}, {\"x\": 17, \"y\": 7, \"val\": 253}, {\"x\": 18, \"y\": 7, \"val\": 253}, {\"x\": 19, \"y\": 7, \"val\": 225}, {\"x\": 20, \"y\": 7, \"val\": 172}, {\"x\": 21, \"y\": 7, \"val\": 253}, {\"x\": 22, \"y\": 7, \"val\": 242}, {\"x\": 23, \"y\": 7, \"val\": 195}, {\"x\": 24, \"y\": 7, \"val\": 64}, {\"x\": 25, \"y\": 7, \"val\": 0}, {\"x\": 26, \"y\": 7, \"val\": 0}, {\"x\": 27, \"y\": 7, \"val\": 0}, {\"x\": 28, \"y\": 7, \"val\": 0}, {\"x\": 1, \"y\": 8, \"val\": 0}, {\"x\": 2, \"y\": 8, \"val\": 0}, {\"x\": 3, \"y\": 8, \"val\": 0}, {\"x\": 4, \"y\": 8, \"val\": 0}, {\"x\": 5, \"y\": 8, \"val\": 0}, {\"x\": 6, \"y\": 8, \"val\": 0}, {\"x\": 7, \"y\": 8, \"val\": 0}, {\"x\": 8, \"y\": 8, \"val\": 49}, {\"x\": 9, \"y\": 8, \"val\": 238}, {\"x\": 10, \"y\": 8, \"val\": 253}, {\"x\": 11, \"y\": 8, \"val\": 253}, {\"x\": 12, \"y\": 8, \"val\": 253}, {\"x\": 13, \"y\": 8, \"val\": 253}, {\"x\": 14, \"y\": 8, \"val\": 253}, {\"x\": 15, \"y\": 8, \"val\": 253}, {\"x\": 16, \"y\": 8, \"val\": 253}, {\"x\": 17, \"y\": 8, \"val\": 253}, {\"x\": 18, \"y\": 8, \"val\": 251}, {\"x\": 19, \"y\": 8, \"val\": 93}, {\"x\": 20, \"y\": 8, \"val\": 82}, {\"x\": 21, \"y\": 8, \"val\": 82}, {\"x\": 22, \"y\": 8, \"val\": 56}, {\"x\": 23, \"y\": 8, \"val\": 39}, {\"x\": 24, \"y\": 8, \"val\": 0}, {\"x\": 25, \"y\": 8, \"val\": 0}, {\"x\": 26, \"y\": 8, \"val\": 0}, {\"x\": 27, \"y\": 8, \"val\": 0}, {\"x\": 28, \"y\": 8, \"val\": 0}, {\"x\": 1, \"y\": 9, \"val\": 0}, {\"x\": 2, \"y\": 9, \"val\": 0}, {\"x\": 3, \"y\": 9, \"val\": 0}, {\"x\": 4, \"y\": 9, \"val\": 0}, {\"x\": 5, \"y\": 9, \"val\": 0}, {\"x\": 6, \"y\": 9, \"val\": 0}, {\"x\": 7, \"y\": 9, \"val\": 0}, {\"x\": 8, \"y\": 9, \"val\": 18}, {\"x\": 9, \"y\": 9, \"val\": 219}, {\"x\": 10, \"y\": 9, \"val\": 253}, {\"x\": 11, \"y\": 9, \"val\": 253}, {\"x\": 12, \"y\": 9, \"val\": 253}, {\"x\": 13, \"y\": 9, \"val\": 253}, {\"x\": 14, \"y\": 9, \"val\": 253}, {\"x\": 15, \"y\": 9, \"val\": 198}, {\"x\": 16, \"y\": 9, \"val\": 182}, {\"x\": 17, \"y\": 9, \"val\": 247}, {\"x\": 18, \"y\": 9, \"val\": 241}, {\"x\": 19, \"y\": 9, \"val\": 0}, {\"x\": 20, \"y\": 9, \"val\": 0}, {\"x\": 21, \"y\": 9, \"val\": 0}, {\"x\": 22, \"y\": 9, \"val\": 0}, {\"x\": 23, \"y\": 9, \"val\": 0}, {\"x\": 24, \"y\": 9, \"val\": 0}, {\"x\": 25, \"y\": 9, \"val\": 0}, {\"x\": 26, \"y\": 9, \"val\": 0}, {\"x\": 27, \"y\": 9, \"val\": 0}, {\"x\": 28, \"y\": 9, \"val\": 0}, {\"x\": 1, \"y\": 10, \"val\": 0}, {\"x\": 2, \"y\": 10, \"val\": 0}, {\"x\": 3, \"y\": 10, \"val\": 0}, {\"x\": 4, \"y\": 10, \"val\": 0}, {\"x\": 5, \"y\": 10, \"val\": 0}, {\"x\": 6, \"y\": 10, \"val\": 0}, {\"x\": 7, \"y\": 10, \"val\": 0}, {\"x\": 8, \"y\": 10, \"val\": 0}, {\"x\": 9, \"y\": 10, \"val\": 80}, {\"x\": 10, \"y\": 10, \"val\": 156}, {\"x\": 11, \"y\": 10, \"val\": 107}, {\"x\": 12, \"y\": 10, \"val\": 253}, {\"x\": 13, \"y\": 10, \"val\": 253}, {\"x\": 14, \"y\": 10, \"val\": 205}, {\"x\": 15, \"y\": 10, \"val\": 11}, {\"x\": 16, \"y\": 10, \"val\": 0}, {\"x\": 17, \"y\": 10, \"val\": 43}, {\"x\": 18, \"y\": 10, \"val\": 154}, {\"x\": 19, \"y\": 10, \"val\": 0}, {\"x\": 20, \"y\": 10, \"val\": 0}, {\"x\": 21, \"y\": 10, \"val\": 0}, {\"x\": 22, \"y\": 10, \"val\": 0}, {\"x\": 23, \"y\": 10, \"val\": 0}, {\"x\": 24, \"y\": 10, \"val\": 0}, {\"x\": 25, \"y\": 10, \"val\": 0}, {\"x\": 26, \"y\": 10, \"val\": 0}, {\"x\": 27, \"y\": 10, \"val\": 0}, {\"x\": 28, \"y\": 10, \"val\": 0}, {\"x\": 1, \"y\": 11, \"val\": 0}, {\"x\": 2, \"y\": 11, \"val\": 0}, {\"x\": 3, \"y\": 11, \"val\": 0}, {\"x\": 4, \"y\": 11, \"val\": 0}, {\"x\": 5, \"y\": 11, \"val\": 0}, {\"x\": 6, \"y\": 11, \"val\": 0}, {\"x\": 7, \"y\": 11, \"val\": 0}, {\"x\": 8, \"y\": 11, \"val\": 0}, {\"x\": 9, \"y\": 11, \"val\": 0}, {\"x\": 10, \"y\": 11, \"val\": 14}, {\"x\": 11, \"y\": 11, \"val\": 1}, {\"x\": 12, \"y\": 11, \"val\": 154}, {\"x\": 13, \"y\": 11, \"val\": 253}, {\"x\": 14, \"y\": 11, \"val\": 90}, {\"x\": 15, \"y\": 11, \"val\": 0}, {\"x\": 16, \"y\": 11, \"val\": 0}, {\"x\": 17, \"y\": 11, \"val\": 0}, {\"x\": 18, \"y\": 11, \"val\": 0}, {\"x\": 19, \"y\": 11, \"val\": 0}, {\"x\": 20, \"y\": 11, \"val\": 0}, {\"x\": 21, \"y\": 11, \"val\": 0}, {\"x\": 22, \"y\": 11, \"val\": 0}, {\"x\": 23, \"y\": 11, \"val\": 0}, {\"x\": 24, \"y\": 11, \"val\": 0}, {\"x\": 25, \"y\": 11, \"val\": 0}, {\"x\": 26, \"y\": 11, \"val\": 0}, {\"x\": 27, \"y\": 11, \"val\": 0}, {\"x\": 28, \"y\": 11, \"val\": 0}, {\"x\": 1, \"y\": 12, \"val\": 0}, {\"x\": 2, \"y\": 12, \"val\": 0}, {\"x\": 3, \"y\": 12, \"val\": 0}, {\"x\": 4, \"y\": 12, \"val\": 0}, {\"x\": 5, \"y\": 12, \"val\": 0}, {\"x\": 6, \"y\": 12, \"val\": 0}, {\"x\": 7, \"y\": 12, \"val\": 0}, {\"x\": 8, \"y\": 12, \"val\": 0}, {\"x\": 9, \"y\": 12, \"val\": 0}, {\"x\": 10, \"y\": 12, \"val\": 0}, {\"x\": 11, \"y\": 12, \"val\": 0}, {\"x\": 12, \"y\": 12, \"val\": 139}, {\"x\": 13, \"y\": 12, \"val\": 253}, {\"x\": 14, \"y\": 12, \"val\": 190}, {\"x\": 15, \"y\": 12, \"val\": 2}, {\"x\": 16, \"y\": 12, \"val\": 0}, {\"x\": 17, \"y\": 12, \"val\": 0}, {\"x\": 18, \"y\": 12, \"val\": 0}, {\"x\": 19, \"y\": 12, \"val\": 0}, {\"x\": 20, \"y\": 12, \"val\": 0}, {\"x\": 21, \"y\": 12, \"val\": 0}, {\"x\": 22, \"y\": 12, \"val\": 0}, {\"x\": 23, \"y\": 12, \"val\": 0}, {\"x\": 24, \"y\": 12, \"val\": 0}, {\"x\": 25, \"y\": 12, \"val\": 0}, {\"x\": 26, \"y\": 12, \"val\": 0}, {\"x\": 27, \"y\": 12, \"val\": 0}, {\"x\": 28, \"y\": 12, \"val\": 0}, {\"x\": 1, \"y\": 13, \"val\": 0}, {\"x\": 2, \"y\": 13, \"val\": 0}, {\"x\": 3, \"y\": 13, \"val\": 0}, {\"x\": 4, \"y\": 13, \"val\": 0}, {\"x\": 5, \"y\": 13, \"val\": 0}, {\"x\": 6, \"y\": 13, \"val\": 0}, {\"x\": 7, \"y\": 13, \"val\": 0}, {\"x\": 8, \"y\": 13, \"val\": 0}, {\"x\": 9, \"y\": 13, \"val\": 0}, {\"x\": 10, \"y\": 13, \"val\": 0}, {\"x\": 11, \"y\": 13, \"val\": 0}, {\"x\": 12, \"y\": 13, \"val\": 11}, {\"x\": 13, \"y\": 13, \"val\": 190}, {\"x\": 14, \"y\": 13, \"val\": 253}, {\"x\": 15, \"y\": 13, \"val\": 70}, {\"x\": 16, \"y\": 13, \"val\": 0}, {\"x\": 17, \"y\": 13, \"val\": 0}, {\"x\": 18, \"y\": 13, \"val\": 0}, {\"x\": 19, \"y\": 13, \"val\": 0}, {\"x\": 20, \"y\": 13, \"val\": 0}, {\"x\": 21, \"y\": 13, \"val\": 0}, {\"x\": 22, \"y\": 13, \"val\": 0}, {\"x\": 23, \"y\": 13, \"val\": 0}, {\"x\": 24, \"y\": 13, \"val\": 0}, {\"x\": 25, \"y\": 13, \"val\": 0}, {\"x\": 26, \"y\": 13, \"val\": 0}, {\"x\": 27, \"y\": 13, \"val\": 0}, {\"x\": 28, \"y\": 13, \"val\": 0}, {\"x\": 1, \"y\": 14, \"val\": 0}, {\"x\": 2, \"y\": 14, \"val\": 0}, {\"x\": 3, \"y\": 14, \"val\": 0}, {\"x\": 4, \"y\": 14, \"val\": 0}, {\"x\": 5, \"y\": 14, \"val\": 0}, {\"x\": 6, \"y\": 14, \"val\": 0}, {\"x\": 7, \"y\": 14, \"val\": 0}, {\"x\": 8, \"y\": 14, \"val\": 0}, {\"x\": 9, \"y\": 14, \"val\": 0}, {\"x\": 10, \"y\": 14, \"val\": 0}, {\"x\": 11, \"y\": 14, \"val\": 0}, {\"x\": 12, \"y\": 14, \"val\": 0}, {\"x\": 13, \"y\": 14, \"val\": 35}, {\"x\": 14, \"y\": 14, \"val\": 241}, {\"x\": 15, \"y\": 14, \"val\": 225}, {\"x\": 16, \"y\": 14, \"val\": 160}, {\"x\": 17, \"y\": 14, \"val\": 108}, {\"x\": 18, \"y\": 14, \"val\": 1}, {\"x\": 19, \"y\": 14, \"val\": 0}, {\"x\": 20, \"y\": 14, \"val\": 0}, {\"x\": 21, \"y\": 14, \"val\": 0}, {\"x\": 22, \"y\": 14, \"val\": 0}, {\"x\": 23, \"y\": 14, \"val\": 0}, {\"x\": 24, \"y\": 14, \"val\": 0}, {\"x\": 25, \"y\": 14, \"val\": 0}, {\"x\": 26, \"y\": 14, \"val\": 0}, {\"x\": 27, \"y\": 14, \"val\": 0}, {\"x\": 28, \"y\": 14, \"val\": 0}, {\"x\": 1, \"y\": 15, \"val\": 0}, {\"x\": 2, \"y\": 15, \"val\": 0}, {\"x\": 3, \"y\": 15, \"val\": 0}, {\"x\": 4, \"y\": 15, \"val\": 0}, {\"x\": 5, \"y\": 15, \"val\": 0}, {\"x\": 6, \"y\": 15, \"val\": 0}, {\"x\": 7, \"y\": 15, \"val\": 0}, {\"x\": 8, \"y\": 15, \"val\": 0}, {\"x\": 9, \"y\": 15, \"val\": 0}, {\"x\": 10, \"y\": 15, \"val\": 0}, {\"x\": 11, \"y\": 15, \"val\": 0}, {\"x\": 12, \"y\": 15, \"val\": 0}, {\"x\": 13, \"y\": 15, \"val\": 0}, {\"x\": 14, \"y\": 15, \"val\": 81}, {\"x\": 15, \"y\": 15, \"val\": 240}, {\"x\": 16, \"y\": 15, \"val\": 253}, {\"x\": 17, \"y\": 15, \"val\": 253}, {\"x\": 18, \"y\": 15, \"val\": 119}, {\"x\": 19, \"y\": 15, \"val\": 25}, {\"x\": 20, \"y\": 15, \"val\": 0}, {\"x\": 21, \"y\": 15, \"val\": 0}, {\"x\": 22, \"y\": 15, \"val\": 0}, {\"x\": 23, \"y\": 15, \"val\": 0}, {\"x\": 24, \"y\": 15, \"val\": 0}, {\"x\": 25, \"y\": 15, \"val\": 0}, {\"x\": 26, \"y\": 15, \"val\": 0}, {\"x\": 27, \"y\": 15, \"val\": 0}, {\"x\": 28, \"y\": 15, \"val\": 0}, {\"x\": 1, \"y\": 16, \"val\": 0}, {\"x\": 2, \"y\": 16, \"val\": 0}, {\"x\": 3, \"y\": 16, \"val\": 0}, {\"x\": 4, \"y\": 16, \"val\": 0}, {\"x\": 5, \"y\": 16, \"val\": 0}, {\"x\": 6, \"y\": 16, \"val\": 0}, {\"x\": 7, \"y\": 16, \"val\": 0}, {\"x\": 8, \"y\": 16, \"val\": 0}, {\"x\": 9, \"y\": 16, \"val\": 0}, {\"x\": 10, \"y\": 16, \"val\": 0}, {\"x\": 11, \"y\": 16, \"val\": 0}, {\"x\": 12, \"y\": 16, \"val\": 0}, {\"x\": 13, \"y\": 16, \"val\": 0}, {\"x\": 14, \"y\": 16, \"val\": 0}, {\"x\": 15, \"y\": 16, \"val\": 45}, {\"x\": 16, \"y\": 16, \"val\": 186}, {\"x\": 17, \"y\": 16, \"val\": 253}, {\"x\": 18, \"y\": 16, \"val\": 253}, {\"x\": 19, \"y\": 16, \"val\": 150}, {\"x\": 20, \"y\": 16, \"val\": 27}, {\"x\": 21, \"y\": 16, \"val\": 0}, {\"x\": 22, \"y\": 16, \"val\": 0}, {\"x\": 23, \"y\": 16, \"val\": 0}, {\"x\": 24, \"y\": 16, \"val\": 0}, {\"x\": 25, \"y\": 16, \"val\": 0}, {\"x\": 26, \"y\": 16, \"val\": 0}, {\"x\": 27, \"y\": 16, \"val\": 0}, {\"x\": 28, \"y\": 16, \"val\": 0}, {\"x\": 1, \"y\": 17, \"val\": 0}, {\"x\": 2, \"y\": 17, \"val\": 0}, {\"x\": 3, \"y\": 17, \"val\": 0}, {\"x\": 4, \"y\": 17, \"val\": 0}, {\"x\": 5, \"y\": 17, \"val\": 0}, {\"x\": 6, \"y\": 17, \"val\": 0}, {\"x\": 7, \"y\": 17, \"val\": 0}, {\"x\": 8, \"y\": 17, \"val\": 0}, {\"x\": 9, \"y\": 17, \"val\": 0}, {\"x\": 10, \"y\": 17, \"val\": 0}, {\"x\": 11, \"y\": 17, \"val\": 0}, {\"x\": 12, \"y\": 17, \"val\": 0}, {\"x\": 13, \"y\": 17, \"val\": 0}, {\"x\": 14, \"y\": 17, \"val\": 0}, {\"x\": 15, \"y\": 17, \"val\": 0}, {\"x\": 16, \"y\": 17, \"val\": 16}, {\"x\": 17, \"y\": 17, \"val\": 93}, {\"x\": 18, \"y\": 17, \"val\": 252}, {\"x\": 19, \"y\": 17, \"val\": 253}, {\"x\": 20, \"y\": 17, \"val\": 187}, {\"x\": 21, \"y\": 17, \"val\": 0}, {\"x\": 22, \"y\": 17, \"val\": 0}, {\"x\": 23, \"y\": 17, \"val\": 0}, {\"x\": 24, \"y\": 17, \"val\": 0}, {\"x\": 25, \"y\": 17, \"val\": 0}, {\"x\": 26, \"y\": 17, \"val\": 0}, {\"x\": 27, \"y\": 17, \"val\": 0}, {\"x\": 28, \"y\": 17, \"val\": 0}, {\"x\": 1, \"y\": 18, \"val\": 0}, {\"x\": 2, \"y\": 18, \"val\": 0}, {\"x\": 3, \"y\": 18, \"val\": 0}, {\"x\": 4, \"y\": 18, \"val\": 0}, {\"x\": 5, \"y\": 18, \"val\": 0}, {\"x\": 6, \"y\": 18, \"val\": 0}, {\"x\": 7, \"y\": 18, \"val\": 0}, {\"x\": 8, \"y\": 18, \"val\": 0}, {\"x\": 9, \"y\": 18, \"val\": 0}, {\"x\": 10, \"y\": 18, \"val\": 0}, {\"x\": 11, \"y\": 18, \"val\": 0}, {\"x\": 12, \"y\": 18, \"val\": 0}, {\"x\": 13, \"y\": 18, \"val\": 0}, {\"x\": 14, \"y\": 18, \"val\": 0}, {\"x\": 15, \"y\": 18, \"val\": 0}, {\"x\": 16, \"y\": 18, \"val\": 0}, {\"x\": 17, \"y\": 18, \"val\": 0}, {\"x\": 18, \"y\": 18, \"val\": 249}, {\"x\": 19, \"y\": 18, \"val\": 253}, {\"x\": 20, \"y\": 18, \"val\": 249}, {\"x\": 21, \"y\": 18, \"val\": 64}, {\"x\": 22, \"y\": 18, \"val\": 0}, {\"x\": 23, \"y\": 18, \"val\": 0}, {\"x\": 24, \"y\": 18, \"val\": 0}, {\"x\": 25, \"y\": 18, \"val\": 0}, {\"x\": 26, \"y\": 18, \"val\": 0}, {\"x\": 27, \"y\": 18, \"val\": 0}, {\"x\": 28, \"y\": 18, \"val\": 0}, {\"x\": 1, \"y\": 19, \"val\": 0}, {\"x\": 2, \"y\": 19, \"val\": 0}, {\"x\": 3, \"y\": 19, \"val\": 0}, {\"x\": 4, \"y\": 19, \"val\": 0}, {\"x\": 5, \"y\": 19, \"val\": 0}, {\"x\": 6, \"y\": 19, \"val\": 0}, {\"x\": 7, \"y\": 19, \"val\": 0}, {\"x\": 8, \"y\": 19, \"val\": 0}, {\"x\": 9, \"y\": 19, \"val\": 0}, {\"x\": 10, \"y\": 19, \"val\": 0}, {\"x\": 11, \"y\": 19, \"val\": 0}, {\"x\": 12, \"y\": 19, \"val\": 0}, {\"x\": 13, \"y\": 19, \"val\": 0}, {\"x\": 14, \"y\": 19, \"val\": 0}, {\"x\": 15, \"y\": 19, \"val\": 46}, {\"x\": 16, \"y\": 19, \"val\": 130}, {\"x\": 17, \"y\": 19, \"val\": 183}, {\"x\": 18, \"y\": 19, \"val\": 253}, {\"x\": 19, \"y\": 19, \"val\": 253}, {\"x\": 20, \"y\": 19, \"val\": 207}, {\"x\": 21, \"y\": 19, \"val\": 2}, {\"x\": 22, \"y\": 19, \"val\": 0}, {\"x\": 23, \"y\": 19, \"val\": 0}, {\"x\": 24, \"y\": 19, \"val\": 0}, {\"x\": 25, \"y\": 19, \"val\": 0}, {\"x\": 26, \"y\": 19, \"val\": 0}, {\"x\": 27, \"y\": 19, \"val\": 0}, {\"x\": 28, \"y\": 19, \"val\": 0}, {\"x\": 1, \"y\": 20, \"val\": 0}, {\"x\": 2, \"y\": 20, \"val\": 0}, {\"x\": 3, \"y\": 20, \"val\": 0}, {\"x\": 4, \"y\": 20, \"val\": 0}, {\"x\": 5, \"y\": 20, \"val\": 0}, {\"x\": 6, \"y\": 20, \"val\": 0}, {\"x\": 7, \"y\": 20, \"val\": 0}, {\"x\": 8, \"y\": 20, \"val\": 0}, {\"x\": 9, \"y\": 20, \"val\": 0}, {\"x\": 10, \"y\": 20, \"val\": 0}, {\"x\": 11, \"y\": 20, \"val\": 0}, {\"x\": 12, \"y\": 20, \"val\": 0}, {\"x\": 13, \"y\": 20, \"val\": 39}, {\"x\": 14, \"y\": 20, \"val\": 148}, {\"x\": 15, \"y\": 20, \"val\": 229}, {\"x\": 16, \"y\": 20, \"val\": 253}, {\"x\": 17, \"y\": 20, \"val\": 253}, {\"x\": 18, \"y\": 20, \"val\": 253}, {\"x\": 19, \"y\": 20, \"val\": 250}, {\"x\": 20, \"y\": 20, \"val\": 182}, {\"x\": 21, \"y\": 20, \"val\": 0}, {\"x\": 22, \"y\": 20, \"val\": 0}, {\"x\": 23, \"y\": 20, \"val\": 0}, {\"x\": 24, \"y\": 20, \"val\": 0}, {\"x\": 25, \"y\": 20, \"val\": 0}, {\"x\": 26, \"y\": 20, \"val\": 0}, {\"x\": 27, \"y\": 20, \"val\": 0}, {\"x\": 28, \"y\": 20, \"val\": 0}, {\"x\": 1, \"y\": 21, \"val\": 0}, {\"x\": 2, \"y\": 21, \"val\": 0}, {\"x\": 3, \"y\": 21, \"val\": 0}, {\"x\": 4, \"y\": 21, \"val\": 0}, {\"x\": 5, \"y\": 21, \"val\": 0}, {\"x\": 6, \"y\": 21, \"val\": 0}, {\"x\": 7, \"y\": 21, \"val\": 0}, {\"x\": 8, \"y\": 21, \"val\": 0}, {\"x\": 9, \"y\": 21, \"val\": 0}, {\"x\": 10, \"y\": 21, \"val\": 0}, {\"x\": 11, \"y\": 21, \"val\": 24}, {\"x\": 12, \"y\": 21, \"val\": 114}, {\"x\": 13, \"y\": 21, \"val\": 221}, {\"x\": 14, \"y\": 21, \"val\": 253}, {\"x\": 15, \"y\": 21, \"val\": 253}, {\"x\": 16, \"y\": 21, \"val\": 253}, {\"x\": 17, \"y\": 21, \"val\": 253}, {\"x\": 18, \"y\": 21, \"val\": 201}, {\"x\": 19, \"y\": 21, \"val\": 78}, {\"x\": 20, \"y\": 21, \"val\": 0}, {\"x\": 21, \"y\": 21, \"val\": 0}, {\"x\": 22, \"y\": 21, \"val\": 0}, {\"x\": 23, \"y\": 21, \"val\": 0}, {\"x\": 24, \"y\": 21, \"val\": 0}, {\"x\": 25, \"y\": 21, \"val\": 0}, {\"x\": 26, \"y\": 21, \"val\": 0}, {\"x\": 27, \"y\": 21, \"val\": 0}, {\"x\": 28, \"y\": 21, \"val\": 0}, {\"x\": 1, \"y\": 22, \"val\": 0}, {\"x\": 2, \"y\": 22, \"val\": 0}, {\"x\": 3, \"y\": 22, \"val\": 0}, {\"x\": 4, \"y\": 22, \"val\": 0}, {\"x\": 5, \"y\": 22, \"val\": 0}, {\"x\": 6, \"y\": 22, \"val\": 0}, {\"x\": 7, \"y\": 22, \"val\": 0}, {\"x\": 8, \"y\": 22, \"val\": 0}, {\"x\": 9, \"y\": 22, \"val\": 23}, {\"x\": 10, \"y\": 22, \"val\": 66}, {\"x\": 11, \"y\": 22, \"val\": 213}, {\"x\": 12, \"y\": 22, \"val\": 253}, {\"x\": 13, \"y\": 22, \"val\": 253}, {\"x\": 14, \"y\": 22, \"val\": 253}, {\"x\": 15, \"y\": 22, \"val\": 253}, {\"x\": 16, \"y\": 22, \"val\": 198}, {\"x\": 17, \"y\": 22, \"val\": 81}, {\"x\": 18, \"y\": 22, \"val\": 2}, {\"x\": 19, \"y\": 22, \"val\": 0}, {\"x\": 20, \"y\": 22, \"val\": 0}, {\"x\": 21, \"y\": 22, \"val\": 0}, {\"x\": 22, \"y\": 22, \"val\": 0}, {\"x\": 23, \"y\": 22, \"val\": 0}, {\"x\": 24, \"y\": 22, \"val\": 0}, {\"x\": 25, \"y\": 22, \"val\": 0}, {\"x\": 26, \"y\": 22, \"val\": 0}, {\"x\": 27, \"y\": 22, \"val\": 0}, {\"x\": 28, \"y\": 22, \"val\": 0}, {\"x\": 1, \"y\": 23, \"val\": 0}, {\"x\": 2, \"y\": 23, \"val\": 0}, {\"x\": 3, \"y\": 23, \"val\": 0}, {\"x\": 4, \"y\": 23, \"val\": 0}, {\"x\": 5, \"y\": 23, \"val\": 0}, {\"x\": 6, \"y\": 23, \"val\": 0}, {\"x\": 7, \"y\": 23, \"val\": 18}, {\"x\": 8, \"y\": 23, \"val\": 171}, {\"x\": 9, \"y\": 23, \"val\": 219}, {\"x\": 10, \"y\": 23, \"val\": 253}, {\"x\": 11, \"y\": 23, \"val\": 253}, {\"x\": 12, \"y\": 23, \"val\": 253}, {\"x\": 13, \"y\": 23, \"val\": 253}, {\"x\": 14, \"y\": 23, \"val\": 195}, {\"x\": 15, \"y\": 23, \"val\": 80}, {\"x\": 16, \"y\": 23, \"val\": 9}, {\"x\": 17, \"y\": 23, \"val\": 0}, {\"x\": 18, \"y\": 23, \"val\": 0}, {\"x\": 19, \"y\": 23, \"val\": 0}, {\"x\": 20, \"y\": 23, \"val\": 0}, {\"x\": 21, \"y\": 23, \"val\": 0}, {\"x\": 22, \"y\": 23, \"val\": 0}, {\"x\": 23, \"y\": 23, \"val\": 0}, {\"x\": 24, \"y\": 23, \"val\": 0}, {\"x\": 25, \"y\": 23, \"val\": 0}, {\"x\": 26, \"y\": 23, \"val\": 0}, {\"x\": 27, \"y\": 23, \"val\": 0}, {\"x\": 28, \"y\": 23, \"val\": 0}, {\"x\": 1, \"y\": 24, \"val\": 0}, {\"x\": 2, \"y\": 24, \"val\": 0}, {\"x\": 3, \"y\": 24, \"val\": 0}, {\"x\": 4, \"y\": 24, \"val\": 0}, {\"x\": 5, \"y\": 24, \"val\": 55}, {\"x\": 6, \"y\": 24, \"val\": 172}, {\"x\": 7, \"y\": 24, \"val\": 226}, {\"x\": 8, \"y\": 24, \"val\": 253}, {\"x\": 9, \"y\": 24, \"val\": 253}, {\"x\": 10, \"y\": 24, \"val\": 253}, {\"x\": 11, \"y\": 24, \"val\": 253}, {\"x\": 12, \"y\": 24, \"val\": 244}, {\"x\": 13, \"y\": 24, \"val\": 133}, {\"x\": 14, \"y\": 24, \"val\": 11}, {\"x\": 15, \"y\": 24, \"val\": 0}, {\"x\": 16, \"y\": 24, \"val\": 0}, {\"x\": 17, \"y\": 24, \"val\": 0}, {\"x\": 18, \"y\": 24, \"val\": 0}, {\"x\": 19, \"y\": 24, \"val\": 0}, {\"x\": 20, \"y\": 24, \"val\": 0}, {\"x\": 21, \"y\": 24, \"val\": 0}, {\"x\": 22, \"y\": 24, \"val\": 0}, {\"x\": 23, \"y\": 24, \"val\": 0}, {\"x\": 24, \"y\": 24, \"val\": 0}, {\"x\": 25, \"y\": 24, \"val\": 0}, {\"x\": 26, \"y\": 24, \"val\": 0}, {\"x\": 27, \"y\": 24, \"val\": 0}, {\"x\": 28, \"y\": 24, \"val\": 0}, {\"x\": 1, \"y\": 25, \"val\": 0}, {\"x\": 2, \"y\": 25, \"val\": 0}, {\"x\": 3, \"y\": 25, \"val\": 0}, {\"x\": 4, \"y\": 25, \"val\": 0}, {\"x\": 5, \"y\": 25, \"val\": 136}, {\"x\": 6, \"y\": 25, \"val\": 253}, {\"x\": 7, \"y\": 25, \"val\": 253}, {\"x\": 8, \"y\": 25, \"val\": 253}, {\"x\": 9, \"y\": 25, \"val\": 212}, {\"x\": 10, \"y\": 25, \"val\": 135}, {\"x\": 11, \"y\": 25, \"val\": 132}, {\"x\": 12, \"y\": 25, \"val\": 16}, {\"x\": 13, \"y\": 25, \"val\": 0}, {\"x\": 14, \"y\": 25, \"val\": 0}, {\"x\": 15, \"y\": 25, \"val\": 0}, {\"x\": 16, \"y\": 25, \"val\": 0}, {\"x\": 17, \"y\": 25, \"val\": 0}, {\"x\": 18, \"y\": 25, \"val\": 0}, {\"x\": 19, \"y\": 25, \"val\": 0}, {\"x\": 20, \"y\": 25, \"val\": 0}, {\"x\": 21, \"y\": 25, \"val\": 0}, {\"x\": 22, \"y\": 25, \"val\": 0}, {\"x\": 23, \"y\": 25, \"val\": 0}, {\"x\": 24, \"y\": 25, \"val\": 0}, {\"x\": 25, \"y\": 25, \"val\": 0}, {\"x\": 26, \"y\": 25, \"val\": 0}, {\"x\": 27, \"y\": 25, \"val\": 0}, {\"x\": 28, \"y\": 25, \"val\": 0}, {\"x\": 1, \"y\": 26, \"val\": 0}, {\"x\": 2, \"y\": 26, \"val\": 0}, {\"x\": 3, \"y\": 26, \"val\": 0}, {\"x\": 4, \"y\": 26, \"val\": 0}, {\"x\": 5, \"y\": 26, \"val\": 0}, {\"x\": 6, \"y\": 26, \"val\": 0}, {\"x\": 7, \"y\": 26, \"val\": 0}, {\"x\": 8, \"y\": 26, \"val\": 0}, {\"x\": 9, \"y\": 26, \"val\": 0}, {\"x\": 10, \"y\": 26, \"val\": 0}, {\"x\": 11, \"y\": 26, \"val\": 0}, {\"x\": 12, \"y\": 26, \"val\": 0}, {\"x\": 13, \"y\": 26, \"val\": 0}, {\"x\": 14, \"y\": 26, \"val\": 0}, {\"x\": 15, \"y\": 26, \"val\": 0}, {\"x\": 16, \"y\": 26, \"val\": 0}, {\"x\": 17, \"y\": 26, \"val\": 0}, {\"x\": 18, \"y\": 26, \"val\": 0}, {\"x\": 19, \"y\": 26, \"val\": 0}, {\"x\": 20, \"y\": 26, \"val\": 0}, {\"x\": 21, \"y\": 26, \"val\": 0}, {\"x\": 22, \"y\": 26, \"val\": 0}, {\"x\": 23, \"y\": 26, \"val\": 0}, {\"x\": 24, \"y\": 26, \"val\": 0}, {\"x\": 25, \"y\": 26, \"val\": 0}, {\"x\": 26, \"y\": 26, \"val\": 0}, {\"x\": 27, \"y\": 26, \"val\": 0}, {\"x\": 28, \"y\": 26, \"val\": 0}, {\"x\": 1, \"y\": 27, \"val\": 0}, {\"x\": 2, \"y\": 27, \"val\": 0}, {\"x\": 3, \"y\": 27, \"val\": 0}, {\"x\": 4, \"y\": 27, \"val\": 0}, {\"x\": 5, \"y\": 27, \"val\": 0}, {\"x\": 6, \"y\": 27, \"val\": 0}, {\"x\": 7, \"y\": 27, \"val\": 0}, {\"x\": 8, \"y\": 27, \"val\": 0}, {\"x\": 9, \"y\": 27, \"val\": 0}, {\"x\": 10, \"y\": 27, \"val\": 0}, {\"x\": 11, \"y\": 27, \"val\": 0}, {\"x\": 12, \"y\": 27, \"val\": 0}, {\"x\": 13, \"y\": 27, \"val\": 0}, {\"x\": 14, \"y\": 27, \"val\": 0}, {\"x\": 15, \"y\": 27, \"val\": 0}, {\"x\": 16, \"y\": 27, \"val\": 0}, {\"x\": 17, \"y\": 27, \"val\": 0}, {\"x\": 18, \"y\": 27, \"val\": 0}, {\"x\": 19, \"y\": 27, \"val\": 0}, {\"x\": 20, \"y\": 27, \"val\": 0}, {\"x\": 21, \"y\": 27, \"val\": 0}, {\"x\": 22, \"y\": 27, \"val\": 0}, {\"x\": 23, \"y\": 27, \"val\": 0}, {\"x\": 24, \"y\": 27, \"val\": 0}, {\"x\": 25, \"y\": 27, \"val\": 0}, {\"x\": 26, \"y\": 27, \"val\": 0}, {\"x\": 27, \"y\": 27, \"val\": 0}, {\"x\": 28, \"y\": 27, \"val\": 0}, {\"x\": 1, \"y\": 28, \"val\": 0}, {\"x\": 2, \"y\": 28, \"val\": 0}, {\"x\": 3, \"y\": 28, \"val\": 0}, {\"x\": 4, \"y\": 28, \"val\": 0}, {\"x\": 5, \"y\": 28, \"val\": 0}, {\"x\": 6, \"y\": 28, \"val\": 0}, {\"x\": 7, \"y\": 28, \"val\": 0}, {\"x\": 8, \"y\": 28, \"val\": 0}, {\"x\": 9, \"y\": 28, \"val\": 0}, {\"x\": 10, \"y\": 28, \"val\": 0}, {\"x\": 11, \"y\": 28, \"val\": 0}, {\"x\": 12, \"y\": 28, \"val\": 0}, {\"x\": 13, \"y\": 28, \"val\": 0}, {\"x\": 14, \"y\": 28, \"val\": 0}, {\"x\": 15, \"y\": 28, \"val\": 0}, {\"x\": 16, \"y\": 28, \"val\": 0}, {\"x\": 17, \"y\": 28, \"val\": 0}, {\"x\": 18, \"y\": 28, \"val\": 0}, {\"x\": 19, \"y\": 28, \"val\": 0}, {\"x\": 20, \"y\": 28, \"val\": 0}, {\"x\": 21, \"y\": 28, \"val\": 0}, {\"x\": 22, \"y\": 28, \"val\": 0}, {\"x\": 23, \"y\": 28, \"val\": 0}, {\"x\": 24, \"y\": 28, \"val\": 0}, {\"x\": 25, \"y\": 28, \"val\": 0}, {\"x\": 26, \"y\": 28, \"val\": 0}, {\"x\": 27, \"y\": 28, \"val\": 0}, {\"x\": 28, \"y\": 28, \"val\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92646a31"
      },
      "source": [
        "The task is to classify the label given an image. To do that, we first need to define a function that creates our model."
      ],
      "id": "92646a31"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f1e837a"
      },
      "source": [
        "Here is what a CNN model looks like. It contains two convolution layers and two max pooling layers."
      ],
      "id": "6f1e837a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:24.227548Z",
          "iopub.status.busy": "2021-08-05T17:06:24.225973Z",
          "iopub.status.idle": "2021-08-05T17:06:24.228879Z",
          "shell.execute_reply": "2021-08-05T17:06:24.229487Z"
        },
        "lines_to_next_cell": 1,
        "id": "c58dac31"
      },
      "source": [
        "def create_cnn_model():\n",
        "    # create model\n",
        "    input_shape = (28, 28, 1)\n",
        "    model = Sequential()\n",
        "    model.add(Reshape(input_shape))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation=\"softmax\")) # output a vector of size 10\n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                   optimizer=\"adam\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "id": "c58dac31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d127cd8"
      },
      "source": [
        "Then we create the model and fit it on training data."
      ],
      "id": "4d127cd8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:06:24.236689Z",
          "iopub.status.busy": "2021-08-05T17:06:24.235929Z",
          "iopub.status.idle": "2021-08-05T17:08:16.821409Z",
          "shell.execute_reply": "2021-08-05T17:08:16.823302Z"
        },
        "id": "8073e929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3573451f-bec3-4e87-c4f3-0f5732674abe"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_cnn_model,\n",
        "                         epochs=2,\n",
        "                         batch_size=20,\n",
        "                         verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features].astype(float),\n",
        "          y=df_train[\"class\"])"
      ],
      "id": "8073e929",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "3000/3000 [==============================] - 61s 20ms/step - loss: 1.1024 - accuracy: 0.8967\n",
            "Epoch 2/2\n",
            "3000/3000 [==============================] - 58s 19ms/step - loss: 0.0767 - accuracy: 0.9782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa554a2a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1436e9d"
      },
      "source": [
        "With a trained model, we can apply it to the test dataset and measure the test accuracy."
      ],
      "id": "e1436e9d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:08:16.843846Z",
          "iopub.status.busy": "2021-08-05T17:08:16.839986Z",
          "iopub.status.idle": "2021-08-05T17:08:19.304624Z",
          "shell.execute_reply": "2021-08-05T17:08:19.305504Z"
        },
        "id": "ed239000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d21c781-cbed-447e-b91f-28363f33bc81"
      },
      "source": [
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)"
      ],
      "id": "ed239000",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 3s 6ms/step\n",
            "accuracy:  0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da05f0d9"
      },
      "source": [
        "### Review Exercise"
      ],
      "id": "da05f0d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10215181"
      },
      "source": [
        "Change the model above to have the kernel size of convolution layers to be (1, 1). How does this affect the performance? Why?"
      ],
      "id": "10215181"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:08:20.416948Z",
          "iopub.status.busy": "2021-08-05T17:08:19.317564Z",
          "iopub.status.idle": "2021-08-05T17:08:56.198841Z",
          "shell.execute_reply": "2021-08-05T17:08:56.199447Z"
        },
        "id": "1392dd02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c52cc6-2c0e-4b21-b58e-33bfd68fbaff"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "#SOLUTION\n",
        "def create_cnn_model():\n",
        "    # create model\n",
        "    input_shape = (28, 28, 1)\n",
        "    model = Sequential()\n",
        "    model.add(Reshape(input_shape))\n",
        "    model.add(Conv2D(32, kernel_size=(1, 1), activation=\"relu\"))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(1, 1), activation=\"relu\"))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation=\"softmax\")) # output a vector of size 10\n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                   optimizer=\"adam\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "    return model\n",
        "model = KerasClassifier(build_fn=create_cnn_model,\n",
        "                         epochs=2,\n",
        "                         batch_size=20,\n",
        "                         verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features].astype(float),\n",
        "          y=df_train[\"class\"])\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)"
      ],
      "id": "1392dd02",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "3000/3000 [==============================] - 40s 13ms/step - loss: 1.3524 - accuracy: 0.7538\n",
            "Epoch 2/2\n",
            "3000/3000 [==============================] - 38s 13ms/step - loss: 0.4753 - accuracy: 0.8502\n",
            "500/500 [==============================] - 2s 4ms/step\n",
            "accuracy:  0.8671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79274762"
      },
      "source": [
        "Change the model above to have the kernel size of the first convolution layer to be (28, 28), and remove other convolution and pooling layers. How does this affect the performance? Why?"
      ],
      "id": "79274762"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:08:56.458063Z",
          "iopub.status.busy": "2021-08-05T17:08:56.457204Z",
          "iopub.status.idle": "2021-08-05T17:09:05.572491Z",
          "shell.execute_reply": "2021-08-05T17:09:05.573017Z"
        },
        "id": "6889ef40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2a9a78-aff6-4ffa-fa06-6d711e69f49d"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "#SOLUTION\n",
        "def create_cnn_model():\n",
        "    # create model\n",
        "    input_shape = (28, 28, 1)\n",
        "    model = Sequential()\n",
        "    model.add(Reshape(input_shape))\n",
        "    model.add(Conv2D(32, kernel_size=(28, 28), activation=\"relu\"))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation=\"softmax\")) # output a vector of size 10\n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                   optimizer=\"adam\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "    return model\n",
        "model = KerasClassifier(build_fn=create_cnn_model,\n",
        "                         epochs=2,\n",
        "                         batch_size=20,\n",
        "                         verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features].astype(float),\n",
        "          y=df_train[\"class\"])\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)"
      ],
      "id": "6889ef40",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 1.2770 - accuracy: 0.6850\n",
            "Epoch 2/2\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 0.4928 - accuracy: 0.8810\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "accuracy:  0.9156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8ec9c9"
      },
      "source": [
        "## Unit A"
      ],
      "id": "7e8ec9c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db980117"
      },
      "source": [
        "### Time Series Classification and Recurrent Neural Networks (RNNs)"
      ],
      "id": "db980117"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6f6fd95"
      },
      "source": [
        "Just like CNNs are suitable for the processing of 2-D images (and 1-D sequences since they can be viewed as a special case of 2-D images), recurrent neural networks (RNNs) are suitable for 1-D sequence modeling."
      ],
      "id": "a6f6fd95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0432e4"
      },
      "source": [
        "Let's start from a concrete sequence classification example, where we want to classify a curve into one of three possible classes: rectangle, triangle, and ellipse:"
      ],
      "id": "6c0432e4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:05.585179Z",
          "iopub.status.busy": "2021-08-05T17:09:05.584249Z",
          "iopub.status.idle": "2021-08-05T17:09:05.699388Z",
          "shell.execute_reply": "2021-08-05T17:09:05.699855Z"
        },
        "id": "135b25b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "b417559f-d551-4127-e1eb-435042098e1b"
      },
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/srush/BT-AI/main/notebooks/shape_classification_train.csv')\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/srush/BT-AI/main/notebooks/shape_classification_train.csv')\n",
        "df_train"
      ],
      "id": "135b25b6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>square</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>square</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>triangle</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>1.040000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>triangle</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>square</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>ellipse</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.359011</td>\n",
              "      <td>0.498888</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.679869</td>\n",
              "      <td>0.745356</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.845905</td>\n",
              "      <td>0.884433</td>\n",
              "      <td>0.916515</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>0.963789</td>\n",
              "      <td>0.979796</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.979796</td>\n",
              "      <td>0.963789</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>0.916515</td>\n",
              "      <td>0.884433</td>\n",
              "      <td>0.845905</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.745356</td>\n",
              "      <td>0.679869</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.498888</td>\n",
              "      <td>0.359011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>ellipse</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.320145</td>\n",
              "      <td>0.446594</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.613784</td>\n",
              "      <td>0.676065</td>\n",
              "      <td>0.729285</td>\n",
              "      <td>0.775312</td>\n",
              "      <td>0.815365</td>\n",
              "      <td>0.850289</td>\n",
              "      <td>0.880695</td>\n",
              "      <td>0.907036</td>\n",
              "      <td>0.929659</td>\n",
              "      <td>0.948829</td>\n",
              "      <td>0.964753</td>\n",
              "      <td>0.977588</td>\n",
              "      <td>0.987456</td>\n",
              "      <td>0.994444</td>\n",
              "      <td>0.998614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998614</td>\n",
              "      <td>0.994444</td>\n",
              "      <td>0.987456</td>\n",
              "      <td>0.977588</td>\n",
              "      <td>0.964753</td>\n",
              "      <td>0.948829</td>\n",
              "      <td>0.929659</td>\n",
              "      <td>0.907036</td>\n",
              "      <td>0.880695</td>\n",
              "      <td>0.850289</td>\n",
              "      <td>0.815365</td>\n",
              "      <td>0.775312</td>\n",
              "      <td>0.729285</td>\n",
              "      <td>0.676065</td>\n",
              "      <td>0.613784</td>\n",
              "      <td>0.539313</td>\n",
              "      <td>0.446594</td>\n",
              "      <td>0.320145</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>square</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>ellipse</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515079</td>\n",
              "      <td>0.699854</td>\n",
              "      <td>0.820652</td>\n",
              "      <td>0.903508</td>\n",
              "      <td>0.958315</td>\n",
              "      <td>0.989743</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989743</td>\n",
              "      <td>0.958315</td>\n",
              "      <td>0.903508</td>\n",
              "      <td>0.820652</td>\n",
              "      <td>0.699854</td>\n",
              "      <td>0.515079</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>triangle</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 56 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         class  0  1  2  3  4    5    6  ...        47   48  49  50  51  52  53  54\n",
              "0       square  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "1       square  0  0  0  0  0  0.0  0.0  ...  1.000000  0.0   0   0   0   0   0   0\n",
              "2     triangle  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "3     triangle  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "4       square  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "...        ... .. .. .. .. ..  ...  ...  ...       ...  ...  ..  ..  ..  ..  ..  ..\n",
              "1195   ellipse  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "1196   ellipse  0  0  0  0  0  0.0  0.0  ...  0.320145  0.0   0   0   0   0   0   0\n",
              "1197    square  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "1198   ellipse  0  0  0  0  0  0.0  0.0  ...  0.000000  0.0   0   0   0   0   0   0\n",
              "1199  triangle  0  0  0  0  0  0.0  0.0  ...  0.071429  0.0   0   0   0   0   0   0\n",
              "\n",
              "[1200 rows x 56 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65ecb073"
      },
      "source": [
        "In this example, the curve is stored as a vector with 55 entries. In the dataframe, the i-th entry of this vector is stored in a column named $i$.\n",
        "As before, we store the names of feature columns in a list `features`."
      ],
      "id": "65ecb073"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:05.704417Z",
          "iopub.status.busy": "2021-08-05T17:09:05.703743Z",
          "iopub.status.idle": "2021-08-05T17:09:05.705900Z",
          "shell.execute_reply": "2021-08-05T17:09:05.706364Z"
        },
        "id": "25af596f"
      },
      "source": [
        "input_length = 55\n",
        "features = []\n",
        "for i in range(input_length):\n",
        "    features.append(str(i))"
      ],
      "id": "25af596f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faafcc8c"
      },
      "source": [
        "We can visualize some examples using the following function."
      ],
      "id": "faafcc8c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:05.714601Z",
          "iopub.status.busy": "2021-08-05T17:09:05.713532Z",
          "iopub.status.idle": "2021-08-05T17:09:06.888048Z",
          "shell.execute_reply": "2021-08-05T17:09:06.888610Z"
        },
        "lines_to_next_cell": 1,
        "id": "c533c279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "1ce0c230-221f-4997-9b4c-3af0b7c92024"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def draw_curve(i):\n",
        "    t = df_train[features].iloc[i]\n",
        "    c = df_train['class'].iloc[i]\n",
        "    plt.plot(list(t))\n",
        "    plt.title(f'class {c}')\n",
        "    plt.show()\n",
        "draw_curve(0)\n",
        "draw_curve(3)\n",
        "draw_curve(5)"
      ],
      "id": "c533c279",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd325f8e"
      },
      "source": [
        "First, let's try to apply an MLP classifier to this problem. Note that we need to set the size of the last layer to be 3 since there are three output classes."
      ],
      "id": "fd325f8e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:06.895019Z",
          "iopub.status.busy": "2021-08-05T17:09:06.894334Z",
          "iopub.status.idle": "2021-08-05T17:09:06.896701Z",
          "shell.execute_reply": "2021-08-05T17:09:06.897173Z"
        },
        "lines_to_next_cell": 1,
        "id": "d2255005"
      },
      "source": [
        "def create_mlp_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax')) # output a vector of size 3\n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "id": "d2255005",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:06.913153Z",
          "iopub.status.busy": "2021-08-05T17:09:06.912128Z",
          "iopub.status.idle": "2021-08-05T17:09:08.379387Z",
          "shell.execute_reply": "2021-08-05T17:09:08.379961Z"
        },
        "lines_to_next_cell": 2,
        "id": "f429bcc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ada55f-7904-484a-ffaf-2704af72bae4"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_mlp_model,\n",
        "                        epochs=10,\n",
        "                        batch_size=20,\n",
        "                        verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features], y=df_train[\"class\"])\n",
        "# print summary\n",
        "print (model.model.summary())\n",
        "# predict on test set\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)"
      ],
      "id": "f429bcc1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 2ms/step - loss: 1.0707 - accuracy: 0.3499\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9794 - accuracy: 0.4853\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.9556 - accuracy: 0.4800\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9145 - accuracy: 0.5051\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.5360\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.5470\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8426 - accuracy: 0.5903\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8201 - accuracy: 0.6059\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7947 - accuracy: 0.6644\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.7720 - accuracy: 0.6689\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (20, 64)                  3584      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (20, 3)                   195       \n",
            "=================================================================\n",
            "Total params: 3,779\n",
            "Trainable params: 3,779\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "60/60 [==============================] - 0s 1ms/step\n",
            "accuracy:  0.6933333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64fb1a76"
      },
      "source": [
        "The accuracy of the MLP classifier is quite low considering the simplicity of this task. The major challenge of this task is that even for the same shapes, the positions where they appear in the sequence, and their sizes may vary. For example, let's look at some rectangles."
      ],
      "id": "64fb1a76"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:08.447397Z",
          "iopub.status.busy": "2021-08-05T17:09:08.446675Z",
          "iopub.status.idle": "2021-08-05T17:09:08.755589Z",
          "shell.execute_reply": "2021-08-05T17:09:08.756066Z"
        },
        "id": "aee11450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "96681bca-793b-4ff3-a24b-e5fa9d6585e1"
      },
      "source": [
        "draw_curve(0)\n",
        "draw_curve(1)\n",
        "draw_curve(4)"
      ],
      "id": "aee11450",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZxUlEQVR4nO3df7Bcd3nf8fdnd++uARsLLGFi/UBOLEhEEyC9MbSmjQMJlaljt9NA7YaEdGjUduKUTAipaTIOuPEMJC0JmThtlIY4hYKrQKAaqlbxgBPSTE10XRNAdpwojh1J/JBs/ANjvHt39+kf55yr1XKv7lr3XK32+/28ZjTePefc3e+x9nnuo+95zn4VEZiZ2exrTHsAZmZWDyd0M7NEOKGbmSXCCd3MLBFO6GZmiXBCNzNLhBO6nbMk/Zik/zPtcZjNCid0M7NEOKGbnSNUcEzaGfOHx6ZO0lZJvy/phKRHJP36Cse9T9IRSU9IulvS3xvZd7mkhXLfVyS9t9x+nqQPlq/7mKSDki5e4fX/raRjkr4m6X5Jry23P0vSbZIelXSvpLdLOjrycyHpspHnt0n6xfLx8yR9ojy3R8vHW0aO/UNJt0j6E+Ap4FslfbukOyR9tRzHG9f2f9hy4YRuUyWpCXwCeAjYDmwGbl/h8IPAy4HnAx8Cfk/SeeW+9wHvi4jnAt8G7C23vxm4ENgKXAT8K+Aby4zjJcANwPdExAXAPwAeLHf/Qvma31Zuf/MzOMUG8DvAi4Bt5XuP/8L6EWA3cAFwArijPL8XANcBvyFp5zN4T8uUE7pN2+XAJcDbI+LrEfF0RCx7ITQiPhgRj0REPyL+I9ABXlLuXgQuk7QxIp6MiLtGtl8EXBYRg4i4OyKeWOblB+Xr7ZQ0FxEPRsRflfveCNwSEV+NiCPAr016cuV4PxoRT0XE14BbgO8dO+y2iDgUEX1gF/BgRPxOeZ73AB8F3jDpe1q+nNBt2rYCD5XJ7LQk/Yyk+yQ9Lukxisp7Y7n7LcCLgT8vp1WuLrd/ADgA3C7pi5J+SdLc+GtHxGHgp4B3Ascl3S7pknL3JcCRkcMfmvTkJD1b0m9KekjSE8CngQ3lv0wqo6/9IuCV5fTQY+V5/jDwwknf0/LlhG7TdgTYJql1uoPK+fKfpaiWnxcRG4DHAQFExF9GxPUU0xTvAT4i6TkRsRgR74qIncDfBa4GfnS594iID0XEqymSapSvA/Alil88lW1jP/oU8OyR56PJ920U/4p4ZTkd9PerUxp965HHR4A/iogNI3/Oj4h/vfz/GbOTnNBt2v6UImG+W9JzyouYVyxz3AVAn2KOuSXpJuC51U5Jb5K0KSKGwGPl5qGk75P0nWVF/ATFFMxw/MUlvUTSayR1gKcp5rqr4/YC7ygvcG4BfnLsxz8L/DNJTUm7OHVK5YLytR6T9HyK+fjT+QTwYkk/Immu/PM9kr5jlZ8zc0K36YqIAfCDwGXA3wBHgX+6zKEHgP8N/AXFlMfTnDpVsQs4JOlJiguk10XENyiq5Y9QJPP7gD+imIYZ1wHeDTwMfJmi0n9Hue9d5Xv+NfAHy/z8W8tzqKZHPj6y71eBZ5Wve1d5Disq59lfR3Ex9IvlWN5Tjs/stOQFLsyeGUlXAh+MiC2rHWt2NrlCNzNLhBO6mVkiPOViZpYIV+hmZok4be/vetq4cWNs3759Wm9vZjaT7r777ocjYtNy+6aW0Ldv387CwsK03t7MbCZJWvFOZU+5mJklwgndzCwRTuhmZolwQjczS4QTuplZIlZN6JLeL+m4pC+ssF+Sfk3SYUmfk/Td9Q/TzMxWM0mFfhvFN9mt5CpgR/lnN/Cf1j4sMzN7plbtQ4+IT0vafppDrgX+axTfIXCXpA2SviUivlTTGG2dHTj0ZQ4de3zaw7CzReKal13CZS84f9ojsZrVcWPRZk79Xuqj5bZvSuiSdlNU8WzbNr7oi03Lz33s8zz8ZA9p9WNt9kXAI092ueUff+e0h2I1O6t3ikbEHmAPwPz8vL8V7Bzxjd6Af/HqS/n5q72wfA6uePeneHrxmxZtsgTU0eVyjFPXW9xSbrMZ0RsMabfc8JSLdqtBb+CEnqI6ongf8KNlt8urgMc9fz47hsNgcRBO6BlpNxt0FwfTHoatg1WnXCR9GLgS2CjpKMUit3MAEfGfgf3A64HDFKuf//P1GqzVr6rUOq3mlEdiZ0tnzhV6qibpcrl+lf0B/ERtI7KzqtsvAtsVej7azQa9vhN6ihzFmev2i396O6Hno91qLP0it7Q4ijNXVWodJ/RsdFqu0FPlKM6cE3p+2k7oyXIUZ25pDr3pj0Iu2q3m0lSbpcVRnLmlCn3OH4VceMolXY7izFXta+2m2xZz4RuL0uWEnrme2xaz0266yyVVjuLMuW0xPx23LSbLUZw5d7nkp5pDL+4JtJQ4ijPnO0XzU/1dLw6c0FPjKM6c2xbzUyV0ty6mx1GcObct5qf6Ija3LqbHUZy5pYTutsVsVBW6WxfT44SeOc+h56eaXut61aLkOIoz5z70/FTTa67Q0+MozlxvMKDVEM2GV4jORVWhew49PU7omesuej3R3JzscnFCT40jOXNeIDo/bltMlyM5c73+0HeJZsZti+lyJGeu13eFnpvqF7gTenocyZnr9oe+SzQznkNPlyM5c93+cOmf4JYHV+jpckLPnC+K5sd3iqbLkZy57uLACT0z7kNPlyM5c72Bu1xy05krptjctpgeR3Lm3LaYH1fo6XIkZ67rtsXszDWLr3lwQk+PIzlzPbctZkeS1xVNlCM5cz23LWap7YSeJCf0zLltMU+dVsNtiwlyJGfObYt5ajcbXuAiQRNFsqRdku6XdFjSjcvs3ybpTkn3SPqcpNfXP1RbD25bzFNnrukKPUGrRrKkJnArcBWwE7he0s6xw34e2BsRrwCuA36j7oFa/YbDYHEQrtAz1G426LkPPTmTRPLlwOGIeCAiesDtwLVjxwTw3PLxhcAX6xuirZeqQnNCz0+71XDbYoImieTNwJGR50fLbaPeCbxJ0lFgP/CTy72QpN2SFiQtnDhx4gyGa3VaWiDabYvZcdtimuqK5OuB2yJiC/B64AOSvum1I2JPRMxHxPymTZtqems7U1WFVt0KbvlwhZ6mSRL6MWDryPMt5bZRbwH2AkTE/wXOAzbWMUBbP9V3eXRcoWen7bbFJE0SyQeBHZIuldSmuOi5b+yYvwFeCyDpOygSuudUznFVheY59Px0Wm5bTNGqkRwRfeAG4ABwH0U3yyFJN0u6pjzsbcCPS/oz4MPAj0VErNegrR5Vhea2xfy0W25bTFFrkoMiYj/Fxc7RbTeNPL4XuKLeodl6c4Wer6Jt0Qk9NY7kjHWd0LNVfJeL+9BT40jOWM9ti9ly22KaHMkZc9tivjpuW0ySE3rGqn9yu0LPT9W26N6FtDiSM+Y59Hx1Wg0iYHHghJ4SR3LGlqZcnNCzU/0Sd+tiWhzJGes6oWfLC0WnyZGcMfeh56u6EO7WxbQ4kjN28k5Rd7nkxhV6mpzQM+YKPV9Lc+hO6ElxJGes2x/QbIhmQ9Meip1lVUL3zUVpcULPWK8/dA96pjpO6ElyNGes1x/SmfNHIEeeckmTozljXVfo2eq4Dz1JjuaM9fpDXxDNVNXZ1F1022JKHM0Z6w6GvqkoU75TNE2O5ox1F4e03YOeJfehp8kJPWO9gadcclVdDHeXS1oczRnr9QeecsmUK/Q0OZoz1ut7Dj1XbltMk6M5Y25bzJcviqbJ0Zwxty3mq/pF7rbFtDiaM9Zz22K2JNFuNei6Qk+KozljRduiPwK56jS9UHRqHM0Zc9ti3jpzDbctJsbRnLGiy8U3FuWq7Qo9OU7oGev2B67QM9ZuOaGnxtGcqeEwWByE2xYz1mk1vaZoYhzNmar6j12h58sVenoczZk6uUC0PwK5arcavrEoMRNFs6Rdku6XdFjSjSsc80ZJ90o6JOlD9Q7T6tZddELPnS+Kpqe12gGSmsCtwA8AR4GDkvZFxL0jx+wA3gFcERGPSnrBeg3Y6uEpF+vMNfj61/vTHobVaJJovhw4HBEPREQPuB24duyYHwdujYhHASLieL3DtLpVlZnbFvPlCj09kyT0zcCRkedHy22jXgy8WNKfSLpL0q7lXkjSbkkLkhZOnDhxZiO2WlTdDa7Q8+WLoumpK5pbwA7gSuB64LckbRg/KCL2RMR8RMxv2rSppre2M1EFstsW81W0LTqhp2SSaD4GbB15vqXcNuoosC8iFiPir4G/oEjwdo5amnKZc0LPVbvlW/9TM0k0HwR2SLpUUhu4Dtg3dszHKapzJG2kmIJ5oMZxWs26rtCz12k16PnGoqSsGs0R0QduAA4A9wF7I+KQpJslXVMedgB4RNK9wJ3A2yPikfUatK3d0pSL59Cz1XEfenJWbVsEiIj9wP6xbTeNPA7gp8s/NgO6TujZq6ZcIgJJ0x6O1cDRnKmqy8Vti/lqNxtEQH8Y0x6K1cQJPVMn+9D9EciVF4pOj6M5U75T1Kpf5u50SYejOVOu0K1dTre5Qk+HozlTvihqnnJJj6M5U75T1E5OubgXPRWO5kz1+kOaDdFyQs9W23PoyXE0Z6rbH7g6z9zSlItvLkqGIzpTvf7Q8+eZ63gOPTmO6Ez1Bk7ouXPbYnoc0ZnqLg7dspi5dtNti6lxRGeq6wo9e9VXJzuhp8MRnalef+iLopmr/v7dtpgOR3Smev0hnTl/MVfOfGNRepzQM9XtD+i4Qs+a2xbT44jOlNsWbanLZdEJPRWO6Ey5bdFcoafHEZ0pty3ayYuiTuipcERnyhW6SaLdaviiaEIc0Zly26IBdJoNty0mxBGdqW5/uHRjieXLFXpaHNGZKip096HnruOEnhQn9Ey5bdGgqNB9UTQdjugMRQS9gbtczFMuqXFEZ8jriVql3Wq4Dz0hjugMVQHsCt06raYr9IQ4ojPUc4VupbbbFpPiiM5QNeXiCt08h54WR3SGXKFbpeMul6Q4ojO0lNDdh549V+hpcULPUDVn6ikXcx96WiaKaEm7JN0v6bCkG09z3D+RFJLm6xui1c1TLlbptJpuW0zIqhEtqQncClwF7ASul7RzmeMuAN4KfKbuQVq9nNCt0mk16C66yyUVk0T05cDhiHggInrA7cC1yxz374H3AE/XOD5bB133oVvJNxalZZKI3gwcGXl+tNy2RNJ3A1sj4n+e7oUk7Za0IGnhxIkTz3iwVo9qyTFX6NZu+qJoStYc0ZIawHuBt612bETsiYj5iJjftGnTWt/azpDvFLVKp9VgGNB3lZ6ESSL6GLB15PmWclvlAuBvAX8o6UHgVcA+Xxg9d7lt0SrVv9Lc6ZKGSRL6QWCHpEsltYHrgH3Vzoh4PCI2RsT2iNgO3AVcExEL6zJiW7OltkUvcJG9pYWindCTsGpER0QfuAE4ANwH7I2IQ5JulnTNeg/Q6neyQndCz12nVfwrzRdG09Ca5KCI2A/sH9t20wrHXrn2Ydl6ctuiVZamXBad0FPgiM6Qv5zLKktTLgP3oqfAEZ2hXn9IQ9DylEv2Or4omhRHdIZ6A68nagV3uaTFUZ2hXn+4dDHM8tZpusslJU7oGer2B67QDXDbYmoc1Rnq9oduWTRgpG3RCT0JjuoMFVMu/qs3z6GnxlGdoW7fF0Wt4LbFtDiqM+QK3Sodz6EnxVGdoZ4rdCt5yiUtjuoMdfsDty0a4C6X1DihZ8g3FlnFd4qmxVGdoZ7bFq3U9o1FSXFUZ8hz6FaRRLvZcIWeCEd1hrrucrER7ZbXFU2FozpDrtBtVKfVcB96IhzVGXJCt1HtVsMLXCTCUZ2hrr9t0Ua0Ww0vQZcIJ/TMRITbFu0UHc+hJ8NRnZmqEvNFUau0W+5ySYWjOjNeT9TGtZuu0FPhqM5MFbiecrFKp9V0Qk+EozozSwndd4paqd1q0PVF0SQ4qjPjCt3GFW2L7kNPgaM6Myfn0N22aAW3LabDCT0zrtBtnNsW0+Gozkx1i7cTulU6bltMhqM6M9Ut3m5btIrbFtPhqM5M1c3gCt0qnTm3LabCUZ0Zty3auOL70N3lkoKJolrSLkn3Szos6cZl9v+0pHslfU7SJyW9qP6hWh2qudLz5pzQrdBuNRgG9N3pMvNWjWpJTeBW4CpgJ3C9pJ1jh90DzEfEdwEfAX6p7oFaPU5W6G5btEJ1PcWti7NvkjLtcuBwRDwQET3gduDa0QMi4s6IeKp8ehewpd5hWl3ctmjjqs+C59Fn3yRRvRk4MvL8aLltJW8B/tdyOyTtlrQgaeHEiROTj9JqU82VOqFbpfosuHVx9tUa1ZLeBMwDv7zc/ojYExHzETG/adOmOt/aJtTzty3amOoCuSv02dea4JhjwNaR51vKbaeQ9P3AzwHfGxHdeoZndfOUi43rzBXXU1yhz75JovogsEPSpZLawHXAvtEDJL0C+E3gmog4Xv8wrS69wRAJWg1Neyh2jqgqdLcuzr5VE3pE9IEbgAPAfcDeiDgk6WZJ15SH/TJwPvB7kj4rad8KL2dTVqwn2kByQrdCxxdFkzHJlAsRsR/YP7btppHH31/zuGyd9PpD31Rkp3BCT4cjOzPd/pC2vzrXRrTdh54MJ/TMdPsDd7jYKZbaFhed0GedIzszvXIO3axSLXbiCn32ObIz0+sP3bJop/CdoulwZGem64RuY07eKeq2xVnnyM6Mp1xsnLtc0uHIzkxv4ArdTuXvckmHIzsz7kO3cSfvFHVCn3WO7MwUbYvuQ7eT/OVc6XBCz4y7XGxco6FioWi3Lc48R3ZmnNBtOe1WwxV6AhzZmXHboi2n3fJC0SlwZGfGbYu2nI4r9CQ4sjPTdduiLcNTLmlwZGckIooK3W2LNqbdbLhtMQGO7IxUXQzVkmNmlc6cK/QUOKFnZGk9UVfoNsZti2lwZGfEC0TbStqthr8PPQGO7IxUc6TucrFx7VaTriv0mefIzogrdFuJ2xbT4MjOSDVH6oRu44q2Rd9YNOsc2Rmp5kh9UdTGddy2mARHdkZ6g6ICc9uijXPbYhqc0DPSdduircBti2lwZGek64uitgK3LabBkZ2RntsWbQWdVtMVegIc2RlxQreVtFsNBsNgMIxpD8XWwJGdEfeh20qqz4QvjM42R3ZGPIduKzm5ULR70WeZIzsj1Y0jXiTaxnXmXKGnwAk9I75T1FZyskJ3Qp9lE0W2pF2S7pd0WNKNy+zvSPrv5f7PSNpe90Bt7XynqK2k+iXvhD7bVo1sSU3gVuAqYCdwvaSdY4e9BXg0Ii4DfgV4T90DtbXrDYZIMNfUtIdi55hqGs5TLrOtNcExlwOHI+IBAEm3A9cC944ccy3wzvLxR4Bfl6SIqL0Hau/BI/zWHz9Q98tm4eEnu7SbDSQndDtV1cr6Lz+4wHm+xrLu/s1rd/CDL7uk9tedJKFvBo6MPD8KvHKlYyKiL+lx4CLg4dGDJO0GdgNs27btjAa84dlz7Lj4/DP62dztuPh8XnrJhdMehp2DXrFtAz/0t7fwVK8/7aFk4cJnza3L606S0GsTEXuAPQDz8/NnVL2/7qUv5HUvfWGt4zLL3YZnt/kPb3jZtIdhazTJ1bFjwNaR51vKbcseI6kFXAg8UscAzcxsMpMk9IPADkmXSmoD1wH7xo7ZB7y5fPxDwKfWY/7czMxWtuqUSzknfgNwAGgC74+IQ5JuBhYiYh/w28AHJB0GvkqR9M3M7CyaaA49IvYD+8e23TTy+GngDfUOzczMngnfYWJmlggndDOzRDihm5klwgndzCwRmlZ3oaQTwENn+OMbGbsLNUGpn6PPb/alfo7n6vm9KCI2Lbdjagl9LSQtRMT8tMexnlI/R5/f7Ev9HGfx/DzlYmaWCCd0M7NEzGpC3zPtAZwFqZ+jz2/2pX6OM3d+MzmHbmZm32xWK3QzMxvjhG5mloiZS+irLVg9ayS9X9JxSV8Y2fZ8SXdI+svyv8+b5hjXQtJWSXdKulfSIUlvLbendI7nSfpTSX9WnuO7yu2XloumHy4XUW9Pe6xrIakp6R5Jnyifp3Z+D0r6vKTPSloot83U53SmEvqEC1bPmtuAXWPbbgQ+GRE7gE+Wz2dVH3hbROwEXgX8RPl3ltI5doHXRMTLgJcDuyS9imKx9F8pF09/lGIx9Vn2VuC+keepnR/A90XEy0f6z2fqczpTCZ2RBasjogdUC1bPrIj4NMV3yI+6Fvjd8vHvAv/orA6qRhHxpYj4f+Xjr1EkhM2kdY4REU+WT+fKPwG8hmLRdJjxc5S0BfiHwH8pn4uEzu80ZupzOmsJfbkFqzdPaSzr6eKI+FL5+MvAxdMcTF0kbQdeAXyGxM6xnI74LHAcuAP4K+CxiKhWXZ71z+qvAj8LDMvnF5HW+UHxS/gPJN1dLmgPM/Y5PauLRNszFxEhaeZ7SyWdD3wU+KmIeKIo8AopnGNEDICXS9oAfAz49ikPqTaSrgaOR8Tdkq6c9njW0asj4pikFwB3SPrz0Z2z8DmdtQp9kgWrU/AVSd8CUP73+JTHsyaS5iiS+X+LiN8vNyd1jpWIeAy4E/g7wIZy0XSY7c/qFcA1kh6kmOZ8DfA+0jk/ACLiWPnf4xS/lC9nxj6ns5bQJ1mwOgWji26/GfgfUxzLmpRzrb8N3BcR7x3ZldI5biorcyQ9C/gBimsFd1Ismg4zfI4R8Y6I2BIR2yli7lMR8cMkcn4Akp4j6YLqMfA64AvM2Od05u4UlfR6ivm8asHqW6Y8pDWR9GHgSoqv6vwK8AvAx4G9wDaKrxh+Y0SMXzidCZJeDfwx8HlOzr/+O4p59FTO8bsoLpg1KYqkvRFxs6Rvpahonw/cA7wpIrrTG+nalVMuPxMRV6d0fuW5fKx82gI+FBG3SLqIGfqczlxCNzOz5c3alIuZma3ACd3MLBFO6GZmiXBCNzNLhBO6mVkinNDNzBLhhG5mloj/DzyQt8oQnYoVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaIElEQVR4nO3df7Bc91nf8fdnd++u88OJE0txsH5YBisGpYWEuThpnYLjgCunwe5MS2qXQOhk0LSDITQh1Gk7JnHrGQLTQBhMGwHBkDRxhUNSTapWeIJJKFMHyXUwkR2DEDaS8kOK4x9JHe/e3X36xzlntV7tjyNrdfecPZ/XjMa755y793usfR49+z3P2a8iAjMzK7/aogdgZmbz4YRuZrYknNDNzJaEE7qZ2ZJwQjczWxJO6GZmS8IJ3QpL0k9I+t+LHodZWTihm5ktCSd0s4JQwjFpz5nfPLZwkrZI+gNJJyU9JunXJxz3AUlHJT0l6T5J/2Bo3xWSDqb7virp/en28yR9JH3dJyQdkHTRhNf/N5KOS/qGpIclvSHd/jxJd0h6XNKDkt4l6djQz4Wky4ae3yHpP6aPXyLpU+m5PZ4+3jx07B9Luk3SnwJPA98u6Tsl3S3p6+k43nx2/4etKpzQbaEk1YFPAY8C24BNwJ0TDj8AvAp4KfBR4PclnZfu+wDwgYh4EfAdwJ50+1uBFwNbgAuBfwl8a8w4LgduAr4vIs4H/iHwSLr7F9LX/I50+1vP4BRrwO8AlwBb0989+g/WjwG7gPOBk8Dd6fm9DLgB+A1JO87gd1pFOaHbol0BXAy8KyL+X0Q8ExFjL4RGxEci4rGI6EbEfwJawOXp7jXgMkkbIuKbEXHv0PYLgcsiohcR90XEU2Nevpe+3g5JKxHxSET8dbrvzcBtEfH1iDgK/Frek0vH+/GIeDoivgHcBvzAyGF3RMShiOgCO4FHIuJ30vO8H/g48CN5f6dVlxO6LdoW4NE0mU0l6eckPSTpSUlPkFTeG9LdbwNeAXwxnVZ5U7r9w8B+4E5JX5L0S5JWRl87Ig4DPwu8Bzgh6U5JF6e7LwaODh3+aN6Tk/R8SR+U9Kikp4DPAhekn0wyw699CfCadHroifQ8fxR4ed7fadXlhG6LdhTYKqkx7aB0vvznSarll0TEBcCTgAAi4q8i4kaSaYr3AXdJekFErEXEeyNiB/D3gTcBPz7ud0TERyPidSRJNdLXAfgyyT88ma0jP/o08Pyh58PJ950knyJek04HfX92SsO/eujxUeAzEXHB0J8XRsS/Gv9/xuwUJ3RbtD8jSZi/KOkF6UXMK8ccdz7QJZljbki6BXhRtlPSWyRtjIg+8ES6uS/p9ZL+bloRP0UyBdMffXFJl0u6WlILeIZkrjs7bg/w7vQC52bgp0d+/PPAP5dUl7STZ0+pnJ++1hOSXkoyHz/Np4BXSPoxSSvpn++T9F0zfs7MCd0WKyJ6wA8DlwF/CxwD/tmYQ/cD/wv4S5Ipj2d49lTFTuCQpG+SXCC9ISK+RVIt30WSzB8CPkMyDTOqBfwi8DXgKySV/rvTfe9Nf+ffAH845uffnp5DNj3yyaF9vwo8L33de9NzmCidZ7+G5GLol9KxvC8dn9lU8gIXZmdG0lXARyJi86xjzdaTK3QzsyXhhG5mtiQ85WJmtiRcoZuZLYmpvb/n0oYNG2Lbtm2L+vVmZqV03333fS0iNo7bt7CEvm3bNg4ePLioX29mVkqSJt6p7CkXM7Ml4YRuZrYknNDNzJaEE7qZ2ZJwQjczWxIzE7qkD0k6IekLE/ZL0q9JOizpAUnfO/9hmpnZLHkq9DtIvslukmuB7emfXcB/PvthmZnZmZrZhx4Rn5W0bcoh1wO/F8l3CNwr6QJJ3xYRX57TGK1AvviVp9j3gP9qq+TVl7yE11/+skUPw3KYx41Fm3j291IfS7edFvWSdpFU8WzdOrroi5XBBz9zhE/cfxxp9rFWfhFwyYXP5/XvckIvg3W9UzQidgO7AVZXV/2tYCX0rU6Pyy86n/3/+vtnH2yld/PHH+Ceh08sehiW0zy6XI7z7PUWN6fbbAl1en2aDTdHVUWzUaPTPW3FPiuoeUTmXuDH026X1wJPev58ebW7PSf0CmnWa7Sd0Etj5pSLpI8BVwEbJB0jWeR2BSAi/guwD3gjcJhk9fN/ca4Ga4vX6fZpOaFXRmvFFXqZ5OlyuXHG/gB+am4jskLrdPu8oLWwL+m0ddas1+n2g14/qNd8JbzoXGrZGWl3+zTrfttURTa95iq9HByZdkY63T6tlfqih2HrpOWEXipO6HZGXKFXS1aht3u9BY/E8nBk2hlpd922WCWDhL7mCr0MHJl2RjrdnrtcKmQw5dJzQi8DR6adkU7PbYtV4jn0cnFkWm4RQcdTLpXiLpdycWRabt1+0A98UbRCmvWko8l3i5aDI9Nyy6q01orfNlWR/V27Qi8HR6bllgW1K/TqyP6uO25bLAVHpuWWfexuNnxjUVW4bbFcnNAtt8GUiy+KVobbFsvFkWm5ZR+73eVSHYMK3XPopeDItNyeWcumXPy2qQon9HJxZFpu2cduJ/TqaKVti+5yKQdHpuXmOfTqcdtiuTgyLbe2E3rlZG2L7a7bFsvAkWm5nepDd9tiVdRqolGTK/SScEK33HynaDW1Gl5XtCwcmZbboG3Rd4pWSrNRcx96STgyLbe22xYrqdmo+U7RknBkWm5ZleaLotXSatRdoZeEI9NyG1wUdUKvlKbn0EvDkWm5tZ3QK6lZr7ltsSQcmZZb21+fW0nNRs23/peEI9Nyy5afk7Toodg6cttieTihW27tbo+Wq/PKcYVeHo5Oy80LRFeTK/TycHRabp1u3y2LFeS2xfJwdFpunZ4r9Cpy22J5ODott/aaE3oVuW2xPHJFp6Sdkh6WdFjSzWP2b5V0j6T7JT0g6Y3zH6otWqfXp+UFoiunteIKvSxmJnRJdeB24FpgB3CjpB0jh/17YE9EvBq4AfiNeQ/UFs8XRaupWXdCL4s80XkFcDgijkREB7gTuH7kmABelD5+MfCl+Q3RiqLd7fmmogpy22J55InOTcDRoefH0m3D3gO8RdIxYB/w0+NeSNIuSQclHTx58uRzGK4tkiv0amo2anT7Qb8fix6KzTCv6LwRuCMiNgNvBD4s6bTXjojdEbEaEasbN26c06+29dJ222IlZddN3LpYfHmi8ziwZej55nTbsLcBewAi4v8A5wEb5jFAKw5X6NWU/Z37O9GLL090HgC2S7pUUpPkoufekWP+FngDgKTvIknonlNZMm0n9EoaJPSeWxeLbmZ0RkQXuAnYDzxE0s1ySNKtkq5LD3sn8JOS/hz4GPATEeEJtyXjtsVqyqbZ3OlSfI08B0XEPpKLncPbbhl6/CBw5XyHZkXjW/+ryQm9PBydllu72/OUSwVlrapuXSw+R6fl1un23YdeQU1X6KXh6LRcur0+/fAC0VXktsXycHRaLl5PtLrctlgejk7LpeOEXlmDKRe3LRaeo9NyyT5uu22xetzlUh5O6JZL9nHbFXr1DKZcnNALz9FpuWQft53Qq8dti+Xh6LRcsmB2l0v1tFY85VIWjk7LxRdFq6tVT9sWndALz9FpuQwqdN9YVDmeQy8PR6fl4gq9unynaHk4Oi2XTtdti1VVr4lGTe5DLwEndMvFd4pWW7NR852iJeDotFzctlhtzUbN3+VSAo5Oy6XjtsVKazVqnkMvAUen5eIpl2prNmrucikBR6fl4i6XamvWXaGXgaPTcvGdotXWatRdoZeAo9NyGVTovrGoknxRtBwcnZZLO11+TtKih2ILkLQtug+96JzQLZdOt+/58wpruUIvBUeo5dLp9Tx/XmFuWywHR6jl0l5zhV5lblssB0eo5dLpOaFXmdsWy8ERarl0un1PuVRYq1F3Qi8BR6jl0vZF0UpLplzc5VJ0jlDLpZO2LVo1NX1RtBQcoZaL2xarzTcWlYMj1HJp9/pe3KLCWo0aa72g349FD8WmyJXQJe2U9LCkw5JunnDMmyU9KOmQpI/Od5i2aO21niv0ChssQ+cqvdAasw6QVAduB34IOAYckLQ3Ih4cOmY78G7gyoh4XNLLztWAbTHctlht2fWTdrfPeSv+pFZUeSL0CuBwRByJiA5wJ3D9yDE/CdweEY8DRMSJ+Q7TFs1ti9XWSpO4L4wWW54I3QQcHXp+LN027BXAKyT9qaR7Je0c90KSdkk6KOngyZMnn9uIbSHaTuiV1hpU6G5dLLJ5RWgD2A5cBdwI/KakC0YPiojdEbEaEasbN26c06+29eC2xWobzKG7Qi+0PBF6HNgy9Hxzum3YMWBvRKxFxN8Af0mS4G1JdLr9wcduq56WL4qWQp6EfgDYLulSSU3gBmDvyDGfJKnOkbSBZArmyBzHaQvW7vZcoVdYVqG315zQi2xmhEZEF7gJ2A88BOyJiEOSbpV0XXrYfuAxSQ8C9wDviojHztWgbX11e3364fVEq8xti+Uws20RICL2AftGtt0y9DiAd6R/bMlkQeyEXl3ZpzPPoRebI9Rmyj5mu8ulurLrJ+5yKTZHqM3kCt1coZeDI9RmyoLYF0Wra3BR1Am90ByhNlMWxG5brK6W+9BLwQndZsrmTV2hV1fLFXopOEJtpqwq80XR6vKdouXgCLWZnNAt+y5896EXmyPUZso+ZrvLpbp8p2g5OEJtpo4TeuXVa6JeE52e+9CLzBFqM7kP3SC5KO459GJzhNpMWZeL1xStttZKzV0uBeeEbjN5ysXAFXoZOEJtJt8papD8g+6EXmyOUJvp1J2ifrtUWatRo+22xUJzhNpMbVfoBjQbdbctFpwj1GbylItBOuXiCr3QHKE2U6fXZ6UuajUteii2QK16jY6/D73QnNBtpvZa3y2L5rbFEnBCt5k6vZ5bFs1tiyXgKLWZOt2+58/NbYsl4Ci1mdrdvlsWLWlbdEIvNEepzeQK3cAVehk4Sm2mTrfvOXRz22IJOEptpk6v78UtjFaj7gq94BylNlN7zRW6JRV6233oheYotZnavT5N96FXXrNeY60X9Pux6KHYBE7oNpMvihoMLRTtefTCcpTaTO1uz22LNriO4tbF4nKU2kydbp+WK/TKyxK6L4wWl6PUZnLbooGnXMrAUWoztbtuW7RTa8q219zpUlS5olTSTkkPSzos6eYpx/0TSSFpdX5DtEVzhW7gCr0MZkappDpwO3AtsAO4UdKOMcedD7wd+Ny8B2mL1ek5odupBU48h15ceaL0CuBwRByJiA5wJ3D9mOP+A/A+4Jk5js8WrNvr0+uHvw/dBp1OTujFlSehbwKODj0/lm4bkPS9wJaI+B/TXkjSLkkHJR08efLkGQ/W1l/28doVumUVutsWi+uso1RSDXg/8M5Zx0bE7ohYjYjVjRs3nu2vtnXg9UQt03TbYuHlidLjwJah55vTbZnzgb8D/LGkR4DXAnt9YXQ5DBK6K/TKa/rGosLLE6UHgO2SLpXUBG4A9mY7I+LJiNgQEdsiYhtwL3BdRBw8JyO2dZUFr9sWbdC26C/oKqyZURoRXeAmYD/wELAnIg5JulXSded6gLZYbVfolvKdosXXyHNQROwD9o1su2XCsVed/bCsKDqu0C3lPvTic5TaVNnHa7ct2uDLudac0IvKCd2m8kVRy7hCLz5HqU3lPnTL+E7R4nOU2lSeQ7dMo16jXpMTeoE5Sm0qd7nYsGbd64oWmaPUpvKdojas2ai5Qi8wR6lN5YuiNqzZqPmiaIE5Sm0qty3asFaj5rbFAnNCt6k8h27Dmo0abVfoheUotamyj9fucjFIrqV4Dr24HKU2Vfbx2hdFDaC1Uve3LRaYo9Sm6vT6rNRFraZFD8UKoFWv0XHbYmE5odtUnW7f1bkNuG2x2BypNlWn6wWi7RS3LRabI9Wmand7blm0AbctFpsTuk3lCt2GuUIvNkeqTdXpOaHbKW5bLDZHqk3VXuu7B90GWis1ty0WmCPVpnKFbsOa9bor9AJzpNpUbbct2hC3LRabI9Wmanf7tFbc5WKJVnpRtN+PRQ/FxnBCt6l8Y5EN87qixeZItak63Z4vitpAywm90BypNpUvitqwQYXuefRCcqTaVG5btGHZe8Gti8XkSLWpXKHbMFfoxeZItal8UdSGNetJx5MTejE5Um2qpG3RbxNLnJpy8XeiF5Ej1Sbq9YNePwZVmZmnXIrNCd0m6niBaBvhhF5suSJV0k5JD0s6LOnmMfvfIelBSQ9I+rSkS+Y/VFtv2cdqd7lYxl0uxTYzUiXVgduBa4EdwI2Sdowcdj+wGhHfDdwF/NK8B2rrzxW6jWo6oRdanki9AjgcEUciogPcCVw/fEBE3BMRT6dP7wU2z3eYtghtJ3Qb4TtFiy1PpG4Cjg49P5Zum+RtwP8ct0PSLkkHJR08efJk/lHaQmQJ3VMulskukLfX3OVSRHONVElvAVaBXx63PyJ2R8RqRKxu3Lhxnr/azoGOE7qNyFpYXaEXUyPHMceBLUPPN6fbnkXSDwL/DviBiGjPZ3i2SFnQesrFMtlNZu5yKaY8kXoA2C7pUklN4AZg7/ABkl4NfBC4LiJOzH+YtgiDi6LuQ7eU2xaLbWZCj4gucBOwH3gI2BMRhyTdKum69LBfBl4I/L6kz0vaO+HlrEQGbYu+U9RSblsstjxTLkTEPmDfyLZbhh7/4JzHZQVwqkJ3QrdEo16jJlfoReVItYnch27jNNNl6Kx4HKk2kfvQbZxmvea2xYJypNpEblu0cVordVfoBeVItYnablu0MZr1mi+KFpQj1SbKPla33LZoQ1oNJ/SickK3ibKP1W5btGHNRs1dLgXlSLWJ3LZo47Sc0AvLkWoTdbp9GjVRq2nRQ7ECcYVeXE7oNlG723eHi52m1ah7TdGCcrTaRJ1u3x0udhrfWFRcjlabyAndxmnWPeVSVI5Wm6jd7Tmh22mablssLEerTdTp9Wk13INuz+Yul+JyQreJOt2+WxbtNO5yKS5Hq03U9hy6jeEpl+JytNpEblu0cVqNuiv0gnK02kTucrFxsrbFiFj0UGyEo9Um6rhCtzGy94R70YvH0WoTtbs9d7nYabyuaHE5odtEnZ6nXOx02XvC8+jF42i1idy2aONk7wkn9OJxtNpEblu0cZqeciksR6tN5IuiNk52XcUVevE4Wm0ity3aOJ5DLy5Hq43V6wfdfjih22lOTbn4O9GLxtFqY2XVl9sWbVTLFXphOaHbWIP1RF2h24hBhe4biwrH0WpjtXvJx2kndBvltsXicrTaWO21dMrFfeg2wneKFpej1cbKvqejteK3iD2b2xaLy9FqYw3m0F2h2wi3LRZXrmiVtFPSw5IOS7p5zP6WpP+W7v+cpG3zHqitr7YvitoEblssrpnRKqkO3A5cC+wAbpS0Y+SwtwGPR8RlwK8A75v3QG19uW3RJnHbYnE1chxzBXA4Io4ASLoTuB54cOiY64H3pI/vAn5dkuIcfAP+ngNH+c0/OTLvl7URT3fc5WLjZe+J3Z89wl33HVvwaMrpZ96wnR/+novn/rp5Evom4OjQ82PAayYdExFdSU8CFwJfGz5I0i5gF8DWrVuf04AveP4K2y964XP6WTszV152Ia+8+EWLHoYVzEq9xs9cfRmHT35z0UMprRc/b+WcvG6ehD43EbEb2A2wurr6nKr3a175cq555cvnOi4zOzPvuObyRQ/Bxsjzefo4sGXo+eZ029hjJDWAFwOPzWOAZmaWT56EfgDYLulSSU3gBmDvyDF7gbemj/8p8EfnYv7czMwmmznlks6J3wTsB+rAhyLikKRbgYMRsRf4beDDkg4DXydJ+mZmto5yzaFHxD5g38i2W4YePwP8yHyHZmZmZ8I9aWZmS8IJ3cxsSTihm5ktCSd0M7MloUV1F0o6CTz6HH98AyN3oS6hZT9Hn1/5Lfs5FvX8LomIjeN2LCyhnw1JByNiddHjOJeW/Rx9fuW37OdYxvPzlIuZ2ZJwQjczWxJlTei7Fz2AdbDs5+jzK79lP8fSnV8p59DNzOx0Za3QzcxshBO6mdmSKF1Cn7VgddlI+pCkE5K+MLTtpZLulvRX6X9fssgxng1JWyTdI+lBSYckvT3dvkzneJ6kP5P05+k5vjfdfmm6aPrhdBH15qLHejYk1SXdL+lT6fNlO79HJP2FpM9LOphuK9X7tFQJPeeC1WVzB7BzZNvNwKcjYjvw6fR5WXWBd0bEDuC1wE+lf2fLdI5t4OqI+B7gVcBOSa8lWSz9V9LF0x8nWUy9zN4OPDT0fNnOD+D1EfGqof7zUr1PS5XQGVqwOiI6QLZgdWlFxGdJvkN+2PXA76aPfxf4x+s6qDmKiC9HxP9NH3+DJCFsYrnOMSIiW2BzJf0TwNUki6ZDyc9R0mbgHwG/lT4XS3R+U5TqfVq2hD5uwepNCxrLuXRRRHw5ffwV4KJFDmZeJG0DXg18jiU7x3Q64vPACeBu4K+BJyKimx5S9vfqrwI/D/TT5xeyXOcHyT/CfyjpvnRBeyjZ+3RdF4m2MxcRIan0vaWSXgh8HPjZiHgqKfASy3COEdEDXiXpAuATwHcueEhzI+lNwImIuE/SVYsezzn0uog4LullwN2Svji8swzv07JV6HkWrF4GX5X0bQDpf08seDxnRdIKSTL/rxHxB+nmpTrHTEQ8AdwD/D3ggnTRdCj3e/VK4DpJj5BMc14NfIDlOT8AIuJ4+t8TJP8oX0HJ3qdlS+h5FqxeBsOLbr8V+O8LHMtZSedafxt4KCLeP7Rrmc5xY1qZI+l5wA+RXCu4h2TRdCjxOUbEuyNic0RsI4m5P4qIH2VJzg9A0gsknZ89Bq4BvkDJ3qelu1NU0htJ5vOyBatvW/CQzoqkjwFXkXxV51eBXwA+CewBtpJ8xfCbI2L0wmkpSHod8CfAX3Bq/vXfksyjL8s5fjfJBbM6SZG0JyJulfTtJBXtS4H7gbdERHtxIz176ZTLz0XEm5bp/NJz+UT6tAF8NCJuk3QhJXqfli6hm5nZeGWbcjEzswmc0M3MloQTupnZknBCNzNbEk7oZmZLwgndzGxJOKGbmS2J/w+5NbUvUfL9sAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b56f345"
      },
      "source": [
        "👩🎓**Student question: Do you think MLPs are suitable for this task? Why or why not?**"
      ],
      "id": "6b56f345"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:08.762479Z",
          "iopub.status.busy": "2021-08-05T17:09:08.761727Z",
          "iopub.status.idle": "2021-08-05T17:09:08.763757Z",
          "shell.execute_reply": "2021-08-05T17:09:08.764232Z"
        },
        "id": "aa38ce8f"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass"
      ],
      "id": "aa38ce8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9177bcdb"
      },
      "source": [
        "### Recurrent Neural Networks (RNNs)"
      ],
      "id": "9177bcdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a74518"
      },
      "source": [
        "Recurrent Neural Networks (RNNs) work by iteratively applying the same base operation to each element in the input sequence. To keep track of what it has seen so far, it also maintains an internal state. We call the base operation an RNN cell. Throughout this lab, we will use a special kind of RNN cell, a Long short-term memory (LSTM) cell due to its empirical successes."
      ],
      "id": "76a74518"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a3ce605"
      },
      "source": [
        "Let's assume that we have a sequence of inputs $x_1, \\ldots, x_T$. (We're notating the input elements as if they are scalars, but you should keep in mind that they might well be vectors themselves.) Let's consider a single update operation at step $t$, where the current internal state is denoted by $h_t$:"
      ],
      "id": "9a3ce605"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7d523c"
      },
      "source": [
        "$h_{t+1} = {\\text{LSTM}}_{\\phi} (h_t, x_t)$,"
      ],
      "id": "ba7d523c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5049ac21"
      },
      "source": [
        "where the LSTM cell has two inputs and one output: it uses both the input element $x_t$ and the old memory $h_t$ to compute the updated memory $h_{t+1}$. $\\phi$ denotes the parameters of the LSTM cell, which we can adjust during training. For simplicy, we omit these parameters througout the rest of this lab. The internal computations of the LSTM cell are beyond the scope of this course, but for anyone interested in knowing further details, [this blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) might be a good starting point."
      ],
      "id": "5049ac21"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "1ecdd0f5"
      },
      "source": [
        "Now that we have defined a single update step, we can chain them together to produce a summary of $x_1, \\ldots, x_T$, starting from $h_0=0$:"
      ],
      "id": "1ecdd0f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a89c773"
      },
      "source": [
        "\\begin{align}\n",
        "h_0 &= 0 \\\\\n",
        "h_1 &= \\text{LSTM} (h_0, x_1) \\\\ \n",
        "h_2 &= \\text{LSTM} (h_1, x_2) \\\\ \n",
        "h_3 &= \\text{LSTM} (h_2, x_3) \\\\ \n",
        "\\vdots\\\\\n",
        "h_T &= \\text{LSTM} (h_{T-1}, x_T) \\\\ \n",
        "\\end{align}\""
      ],
      "id": "6a89c773"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4f8a697"
      },
      "source": [
        "$h_T$ can be used as a feature representation for the entire input sequence $x_1, \\ldots, x_T$."
      ],
      "id": "a4f8a697"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37b12eeb"
      },
      "source": [
        "In `Keras`, the API for an LSTM cell is\n",
        "```\n",
        "LSTM(\n",
        "    units,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    time_major=False,\n",
        "    unroll=False,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "It appears intimidating, but we only need to set `units` in this lab. In a nutshell, it controls the size of the hidden states in the LSTM cell: the larger the size, the more powerful the model will be, but the more likely the model will overfit to training data (overfitting means memorizing the training data without being able to generlize to the test data)."
      ],
      "id": "37b12eeb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:08.774585Z",
          "iopub.status.busy": "2021-08-05T17:09:08.773870Z",
          "iopub.status.idle": "2021-08-05T17:09:08.776600Z",
          "shell.execute_reply": "2021-08-05T17:09:08.775898Z"
        },
        "id": "c21ece53"
      },
      "source": [
        "from keras.layers import LSTM\n",
        "hidden_size = 32\n",
        "lstm_layer = LSTM(hidden_size)"
      ],
      "id": "c21ece53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a4117b5"
      },
      "source": [
        "This layer can be applied to a sequence of inputs $x_1, \\ldots, x_T$, and the output will be the final hidden state $h_T$. Below shows an example of how to use this layer. Note that we need to use a `Reshape` layer to add one additional dimension to the input sequence since the expected input shape of the LSTM layer is `sequence_length x input size`, and the `input_size` in the case is 1 since $x_t$'s are scalars is 1."
      ],
      "id": "9a4117b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:08.788384Z",
          "iopub.status.busy": "2021-08-05T17:09:08.787450Z",
          "iopub.status.idle": "2021-08-05T17:09:09.086880Z",
          "shell.execute_reply": "2021-08-05T17:09:09.087433Z"
        },
        "lines_to_next_cell": 2,
        "id": "f9ee4a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cff3a5-393a-46c4-8f4f-7c27a8df3187"
      },
      "source": [
        "input_shape = (input_length, 1)\n",
        "model = Sequential()\n",
        "model.add(Reshape(input_shape))\n",
        "model.add(lstm_layer)\n",
        "#\n",
        "# take the first example as input\n",
        "# input shape: num samples x input_length\n",
        "# output shape: num samples x hidden size\n",
        "inputs = tf.convert_to_tensor(df_train[features].iloc[:1])\n",
        "output = model(inputs)\n",
        "print (inputs.shape)\n",
        "print (output.shape)"
      ],
      "id": "f9ee4a96",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 55)\n",
            "(1, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "353e38d2"
      },
      "source": [
        "# Group Exercise A"
      ],
      "id": "353e38d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51f1cb6f"
      },
      "source": [
        "## Question 0"
      ],
      "id": "51f1cb6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1913e6a"
      },
      "source": [
        "Icebreakers"
      ],
      "id": "d1913e6a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06b11fb3"
      },
      "source": [
        "Who are other members of your group today?"
      ],
      "id": "06b11fb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN3gFEwYs_T-"
      },
      "source": [
        "Karina, Nadiia and Esther"
      ],
      "id": "AN3gFEwYs_T-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "06ac3cfc"
      },
      "source": [
        "📝📝📝📝 FILLME"
      ],
      "id": "06ac3cfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8084dabb"
      },
      "source": [
        "* What's their favorite place?"
      ],
      "id": "8084dabb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x6VXTZuDMXO"
      },
      "source": [
        "Own room and the park"
      ],
      "id": "7x6VXTZuDMXO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "629b249d"
      },
      "source": [
        "📝📝📝📝 FILLME"
      ],
      "id": "629b249d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01c0c10f"
      },
      "source": [
        "* What are their goals by the end of the decade?"
      ],
      "id": "01c0c10f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw39SJLDDQ3u"
      },
      "source": [
        "To find an internship/job and start own company"
      ],
      "id": "Rw39SJLDDQ3u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019871dc"
      },
      "source": [
        "📝📝📝📝 FILLME"
      ],
      "id": "019871dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cb9d91d"
      },
      "source": [
        "## Question 1"
      ],
      "id": "4cb9d91d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f73012d4"
      },
      "source": [
        "Look at this figure again. Can you figure out where are $h_t$'s and $x_t$'s? (Don't worry if you not understand the entire diagram does for now, we will elaborate on it later)**"
      ],
      "id": "f73012d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5da6e76"
      },
      "source": [
        "![image](https://www.researchgate.net/profile/Huy-Tien-Nguyen/publication/321259272/figure/fig2/AS:572716866433034@1513557749934/Illustration-of-our-LSTM-model-for-sentiment-classification-Each-word-is-transfered-to-a_W640.jpg)"
      ],
      "id": "f5da6e76"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:09.092539Z",
          "iopub.status.busy": "2021-08-05T17:09:09.091660Z",
          "iopub.status.idle": "2021-08-05T17:09:09.093827Z",
          "shell.execute_reply": "2021-08-05T17:09:09.094423Z"
        },
        "id": "bc8004b3"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# The ht's xt's are in the long-short term memory networks and sequence of neural networks."
      ],
      "id": "bc8004b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19d95683"
      },
      "source": [
        "Why can LSTMs process variable length inputs?"
      ],
      "id": "19d95683"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:09.098765Z",
          "iopub.status.busy": "2021-08-05T17:09:09.097941Z",
          "iopub.status.idle": "2021-08-05T17:09:09.099981Z",
          "shell.execute_reply": "2021-08-05T17:09:09.100678Z"
        },
        "id": "4b1f01cc"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "#The LSTMs process variable length inputs step by step."
      ],
      "id": "4b1f01cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3900ac9"
      },
      "source": [
        "## Question 2"
      ],
      "id": "c3900ac9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d8abbb1"
      },
      "source": [
        "Modify the MLP code to use LSTM instead. We recommend using a hidden size of 32 or 64. Train the model and report the test accuracy. You should expect to see at least 90% accuracy. Hint: don't forget the reshape layer before the LSTM!"
      ],
      "id": "6d8abbb1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:09.118319Z",
          "iopub.status.busy": "2021-08-05T17:09:09.116720Z",
          "iopub.status.idle": "2021-08-05T17:09:24.092518Z",
          "shell.execute_reply": "2021-08-05T17:09:24.092971Z"
        },
        "id": "c91bf44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706e8b81-5a35-40cf-e912-daf7b7eaec11"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "def create_rnn_model():\n",
        "    tf.random.set_seed(1234)\n",
        "    # create model\n",
        "    input_shape = (input_length, 1)\n",
        "    model = Sequential()\n",
        "    model.add(Reshape(input_shape))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(3, activation='softmax')) # output a vector of size 3\n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                   optimizer=\"adam\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_rnn_model,\n",
        "                         epochs=10,\n",
        "                         batch_size=20,\n",
        "                         verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features], y=df_train[\"class\"])\n",
        "# print summary\n",
        "print (model.model.summary())\n",
        "# predict on test set\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)"
      ],
      "id": "c91bf44b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 3s 14ms/step - loss: 1.0924 - accuracy: 0.3909\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.8978 - accuracy: 0.5822\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.7772 - accuracy: 0.6318\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.6576 - accuracy: 0.7066\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 0.4706 - accuracy: 0.8408\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 1.0184 - accuracy: 0.5086\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 0.5751 - accuracy: 0.7174\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 0.4743 - accuracy: 0.8543\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 0.3043 - accuracy: 0.9343\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 0.1980 - accuracy: 0.9595\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_10 (Reshape)         (20, 55, 1)               0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (20, 32)                  4352      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (20, 3)                   99        \n",
            "=================================================================\n",
            "Total params: 4,451\n",
            "Trainable params: 4,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "60/60 [==============================] - 1s 6ms/step\n",
            "accuracy:  0.9283333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71a4f791"
      },
      "source": [
        "## Unit B"
      ],
      "id": "71a4f791"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56129e9e"
      },
      "source": [
        "### Recurrent Neural Networks for Text Classification"
      ],
      "id": "56129e9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80397890"
      },
      "source": [
        "Now let's go to a real application: text classification. Text classification raises new challenges, as the inputs are strings instead of the numeric values we have been familiar with in this course. In this unit, we will first find a suitable feature representation for the text input, and then we will apply an LSTM-based model to this task."
      ],
      "id": "80397890"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd13fc6d"
      },
      "source": [
        "The text classification task we will be working with is sentiment analysis,  where the goal is to classify the sentiment of a text sequence. In particular, we will use the Stanford Sentiment Treebank v2 (SST-2) dataset, where we want to predict the sentiment (positive or negative) for a movie review."
      ],
      "id": "fd13fc6d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "FnriKLOO2aRX",
        "outputId": "07a495d6-7852-4b54-a399-39f4c5402466"
      },
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/srush/BT-AI/main/notebooks/sst_movie_reviews_processed_train.csv.gz', compression='gzip')\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/srush/BT-AI/main/notebooks/sst_movie_reviews_processed_test.csv.gz', compression='gzip')\n",
        "df_train[:10]"
      ],
      "id": "FnriKLOO2aRX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>an</td>\n",
              "      <td>ambitious</td>\n",
              "      <td>'</td>\n",
              "      <td>what</td>\n",
              "      <td>if</td>\n",
              "      <td>?</td>\n",
              "      <td>'</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>a</td>\n",
              "      <td>great</td>\n",
              "      <td>cast</td>\n",
              "      <td>and</td>\n",
              "      <td>a</td>\n",
              "      <td>wonderful</td>\n",
              "      <td>but</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>confusing</td>\n",
              "      <td>OOV</td>\n",
              "      <td>movie</td>\n",
              "      <td>about</td>\n",
              "      <td>growing</td>\n",
              "      <td>up</td>\n",
              "      <td>in</td>\n",
              "      <td>a</td>\n",
              "      <td>dysfunctional</td>\n",
              "      <td>family</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>remarkable</td>\n",
              "      <td>for</td>\n",
              "      <td>its</td>\n",
              "      <td>intelligence</td>\n",
              "      <td>and</td>\n",
              "      <td>intensity</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>steven</td>\n",
              "      <td>soderbergh</td>\n",
              "      <td>'</td>\n",
              "      <td>s</td>\n",
              "      <td>digital</td>\n",
              "      <td>video</td>\n",
              "      <td>experiment</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>clever</td>\n",
              "      <td>and</td>\n",
              "      <td>cutting</td>\n",
              "      <td>,</td>\n",
              "      <td>quick</td>\n",
              "      <td>and</td>\n",
              "      <td>dirty</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "      <td>modern</td>\n",
              "      <td>living</td>\n",
              "      <td>and</td>\n",
              "      <td>movie</td>\n",
              "      <td>life</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>a</td>\n",
              "      <td>whole</td>\n",
              "      <td>lot</td>\n",
              "      <td>of</td>\n",
              "      <td>fun</td>\n",
              "      <td>and</td>\n",
              "      <td>funny</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>middle</td>\n",
              "      <td>,</td>\n",
              "      <td>though</td>\n",
              "      <td>somewhat</td>\n",
              "      <td>less</td>\n",
              "      <td>OOV</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>start</td>\n",
              "      <td>and</td>\n",
              "      <td>finish</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>positive</td>\n",
              "      <td>constantly</td>\n",
              "      <td>touching</td>\n",
              "      <td>,</td>\n",
              "      <td>surprisingly</td>\n",
              "      <td>funny</td>\n",
              "      <td>,</td>\n",
              "      <td>OOV</td>\n",
              "      <td>exploration</td>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>creative</td>\n",
              "      <td>act</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>negative</td>\n",
              "      <td>it</td>\n",
              "      <td>'</td>\n",
              "      <td>s</td>\n",
              "      <td>as</td>\n",
              "      <td>if</td>\n",
              "      <td>allen</td>\n",
              "      <td>,</td>\n",
              "      <td>at</td>\n",
              "      <td>OOV</td>\n",
              "      <td>,</td>\n",
              "      <td>has</td>\n",
              "      <td>OOV</td>\n",
              "      <td>challenging</td>\n",
              "      <td>himself</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>negative</td>\n",
              "      <td>check</td>\n",
              "      <td>your</td>\n",
              "      <td>brain</td>\n",
              "      <td>and</td>\n",
              "      <td>your</td>\n",
              "      <td>secret</td>\n",
              "      <td>agent</td>\n",
              "      <td>OOV</td>\n",
              "      <td>ring</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>door</td>\n",
              "      <td>because</td>\n",
              "      <td>you</td>\n",
              "      <td>don</td>\n",
              "      <td>'</td>\n",
              "      <td>t</td>\n",
              "      <td>want</td>\n",
              "      <td>to</td>\n",
              "      <td>think</td>\n",
              "      <td>too</td>\n",
              "      <td>much</td>\n",
              "      <td>about</td>\n",
              "      <td>what</td>\n",
              "      <td>'</td>\n",
              "      <td>s</td>\n",
              "      <td>going</td>\n",
              "      <td>on</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>negative</td>\n",
              "      <td>it</td>\n",
              "      <td>'</td>\n",
              "      <td>s</td>\n",
              "      <td>just</td>\n",
              "      <td>hard</td>\n",
              "      <td>to</td>\n",
              "      <td>believe</td>\n",
              "      <td>that</td>\n",
              "      <td>a</td>\n",
              "      <td>life</td>\n",
              "      <td>like</td>\n",
              "      <td>this</td>\n",
              "      <td>can</td>\n",
              "      <td>sound</td>\n",
              "      <td>so</td>\n",
              "      <td>dull</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>negative</td>\n",
              "      <td>the</td>\n",
              "      <td>rollerball</td>\n",
              "      <td>sequences</td>\n",
              "      <td>feel</td>\n",
              "      <td>OOV</td>\n",
              "      <td>and</td>\n",
              "      <td>OOV</td>\n",
              "      <td>.</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "      <td>PAD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class           0           1          2  ...   51   52   53   54\n",
              "0  positive          an   ambitious          '  ...  PAD  PAD  PAD  PAD\n",
              "1  positive           a       great       cast  ...  PAD  PAD  PAD  PAD\n",
              "2  positive  remarkable         for        its  ...  PAD  PAD  PAD  PAD\n",
              "3  positive      steven  soderbergh          '  ...  PAD  PAD  PAD  PAD\n",
              "4  positive           a       whole        lot  ...  PAD  PAD  PAD  PAD\n",
              "5  positive  constantly    touching          ,  ...  PAD  PAD  PAD  PAD\n",
              "6  negative          it           '          s  ...  PAD  PAD  PAD  PAD\n",
              "7  negative       check        your      brain  ...  PAD  PAD  PAD  PAD\n",
              "8  negative          it           '          s  ...  PAD  PAD  PAD  PAD\n",
              "9  negative         the  rollerball  sequences  ...  PAD  PAD  PAD  PAD\n",
              "\n",
              "[10 rows x 56 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6e58504"
      },
      "source": [
        "The column `class` stores the sentiment of each review, which is either \"positive\" or \"negative\"."
      ],
      "id": "d6e58504"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.240120Z",
          "iopub.status.busy": "2021-08-05T17:09:24.239278Z",
          "iopub.status.idle": "2021-08-05T17:09:24.242254Z",
          "shell.execute_reply": "2021-08-05T17:09:24.242759Z"
        },
        "id": "ad4589d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b785fba3-1f4f-450f-db95-ab5bccdc5fcc"
      },
      "source": [
        "df_train[:100][\"class\"].unique()"
      ],
      "id": "ad4589d8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf9b8233"
      },
      "source": [
        "The other columns store the words, where the i-th word is stored in a feature column i (counting from 0). For example, the first word of each movie review is stored in column 0, the second word is stored in column 1, and so on. As before, we store all feature column names in a list. The maximum length of sentences is 55 on this dataset, so we have 55 feature columns."
      ],
      "id": "bf9b8233"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.247520Z",
          "iopub.status.busy": "2021-08-05T17:09:24.246802Z",
          "iopub.status.idle": "2021-08-05T17:09:24.249087Z",
          "shell.execute_reply": "2021-08-05T17:09:24.249579Z"
        },
        "id": "9ae4a496"
      },
      "source": [
        "input_length = 55\n",
        "features = []\n",
        "for i in range(input_length):\n",
        "    features.append(str(i))"
      ],
      "id": "9ae4a496",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28526b5b"
      },
      "source": [
        "Notice that some tokens towards the end are `PAD`. They are actually placeholders to pad every sentence into the same length such that we can store them in a table."
      ],
      "id": "28526b5b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.255567Z",
          "iopub.status.busy": "2021-08-05T17:09:24.254622Z",
          "iopub.status.idle": "2021-08-05T17:09:24.262030Z",
          "shell.execute_reply": "2021-08-05T17:09:24.262817Z"
        },
        "id": "0435c4ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2627284f-8a60-4bc5-9a34-aac5c2bcea32"
      },
      "source": [
        "data = df_train[features].values\n",
        "labels = df_train['class'].values\n",
        "print (labels[1], data[1])\n",
        "print (labels[8], data[8])"
      ],
      "id": "0435c4ae",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive ['a' 'great' 'cast' 'and' 'a' 'wonderful' 'but' 'sometimes' 'confusing'\n",
            " 'OOV' 'movie' 'about' 'growing' 'up' 'in' 'a' 'dysfunctional' 'family'\n",
            " '.' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD']\n",
            "negative ['it' \"'\" 's' 'just' 'hard' 'to' 'believe' 'that' 'a' 'life' 'like' 'this'\n",
            " 'can' 'sound' 'so' 'dull' '.' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD'\n",
            " 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD' 'PAD']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47daf292"
      },
      "source": [
        "### Input Representation"
      ],
      "id": "47daf292"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cb7049d"
      },
      "source": [
        "Different from all examples we've seen so far, the input in text classification cannot be directly fed into a neural network, since they are strings but not numeric values. A natural idea is to associate each word type with an integer id, such that we can use those integer ids to represent words."
      ],
      "id": "4cb7049d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e14ac04"
      },
      "source": [
        "First, we need to build the mapping from word types to integer ids."
      ],
      "id": "5e14ac04"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.318576Z",
          "iopub.status.busy": "2021-08-05T17:09:24.312287Z",
          "iopub.status.idle": "2021-08-05T17:09:24.321053Z",
          "shell.execute_reply": "2021-08-05T17:09:24.321584Z"
        },
        "id": "257d3cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdc4902-c72e-49a0-a4ae-c428f45979f7"
      },
      "source": [
        "# build vocabulary\n",
        "word2id = {}\n",
        "id2word = {}\n",
        "unassigned_id = 0\n",
        "for review in data:\n",
        "    for token in review:\n",
        "        if token not in word2id:\n",
        "            word2id[token] = unassigned_id\n",
        "            id2word[unassigned_id] = token\n",
        "            unassigned_id += 1\n",
        "vocab_size = len(word2id)\n",
        "print ('Vocab size: ', vocab_size)"
      ],
      "id": "257d3cbc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:  4823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "441eaae9"
      },
      "source": [
        "With `word2id`, we can map a word to its associated id:"
      ],
      "id": "441eaae9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.326103Z",
          "iopub.status.busy": "2021-08-05T17:09:24.325400Z",
          "iopub.status.idle": "2021-08-05T17:09:24.327936Z",
          "shell.execute_reply": "2021-08-05T17:09:24.328388Z"
        },
        "id": "8772831c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76b7ebe-9b49-4f51-c30c-d598084a6e88"
      },
      "source": [
        "print (word2id['the'])"
      ],
      "id": "8772831c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06b6a8b9"
      },
      "source": [
        "With `id2word`, we can map an integer id to the corresponding word:"
      ],
      "id": "06b6a8b9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.332980Z",
          "iopub.status.busy": "2021-08-05T17:09:24.332171Z",
          "iopub.status.idle": "2021-08-05T17:09:24.334995Z",
          "shell.execute_reply": "2021-08-05T17:09:24.335469Z"
        },
        "lines_to_next_cell": 2,
        "id": "f999f48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dd4d66-4a4b-4c7b-a5c8-cccaf18ce8fe"
      },
      "source": [
        "print (id2word[51])"
      ],
      "id": "f999f48d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584f767a"
      },
      "source": [
        "👩🎓**Student question: Convert the sentence \"a great cast\" to a sequence of integer ids using `word2id`.**"
      ],
      "id": "584f767a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.340693Z",
          "iopub.status.busy": "2021-08-05T17:09:24.339935Z",
          "iopub.status.idle": "2021-08-05T17:09:24.342688Z",
          "shell.execute_reply": "2021-08-05T17:09:24.343158Z"
        },
        "id": "c4a4fe57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea9a30f-deca-4f04-d1b3-8de71b01b5f2"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "print (word2id['a'], word2id['great'], word2id['cast'])"
      ],
      "id": "c4a4fe57",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 8 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d28fe4d"
      },
      "source": [
        "👩🎓**Student question: Convert a sequence of integer ids `[7, 8, 9]` to the original sentence.**"
      ],
      "id": "2d28fe4d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.350436Z",
          "iopub.status.busy": "2021-08-05T17:09:24.349653Z",
          "iopub.status.idle": "2021-08-05T17:09:24.352396Z",
          "shell.execute_reply": "2021-08-05T17:09:24.352879Z"
        },
        "lines_to_next_cell": 1,
        "id": "1eb9d21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2841cb-6162-4460-e30f-298ca4f4f2f3"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "pass\n",
        "print (id2word[7], id2word[8], id2word[9])"
      ],
      "id": "1eb9d21d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a great cast\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823e016e"
      },
      "source": [
        "Now we can convert all the strings into integer ids using those mappings."
      ],
      "id": "823e016e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.358498Z",
          "iopub.status.busy": "2021-08-05T17:09:24.357788Z",
          "iopub.status.idle": "2021-08-05T17:09:24.648631Z",
          "shell.execute_reply": "2021-08-05T17:09:24.651111Z"
        },
        "id": "46b517ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "7c1423c4-34e7-48a0-e604-484bbcf9f164"
      },
      "source": [
        "def word_to_id(word):\n",
        "    return word2id[word]\n",
        "df_train[features] = df_train[features].applymap(word_to_id)\n",
        "df_test[features] = df_test[features].applymap(word_to_id)\n",
        "df_train[:10]"
      ],
      "id": "46b517ca",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>36</td>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>45</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>38</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>55</td>\n",
              "      <td>15</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>10</td>\n",
              "      <td>57</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>positive</td>\n",
              "      <td>58</td>\n",
              "      <td>59</td>\n",
              "      <td>38</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>61</td>\n",
              "      <td>48</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>63</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>negative</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>38</td>\n",
              "      <td>42</td>\n",
              "      <td>15</td>\n",
              "      <td>38</td>\n",
              "      <td>67</td>\n",
              "      <td>15</td>\n",
              "      <td>68</td>\n",
              "      <td>69</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>negative</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>72</td>\n",
              "      <td>10</td>\n",
              "      <td>71</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>76</td>\n",
              "      <td>77</td>\n",
              "      <td>78</td>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>81</td>\n",
              "      <td>82</td>\n",
              "      <td>83</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>86</td>\n",
              "      <td>87</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>negative</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>82</td>\n",
              "      <td>90</td>\n",
              "      <td>91</td>\n",
              "      <td>7</td>\n",
              "      <td>45</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>94</td>\n",
              "      <td>95</td>\n",
              "      <td>96</td>\n",
              "      <td>97</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>98</td>\n",
              "      <td>99</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class   0   1   2    3   4   5   6  ...  47  48  49  50  51  52  53  54\n",
              "0  positive   0   1   2    3   4   5   2  ...   6   6   6   6   6   6   6   6\n",
              "1  positive   7   8   9   10   7  11  12  ...   6   6   6   6   6   6   6   6\n",
              "2  positive  24  25  26   27  10  28  23  ...   6   6   6   6   6   6   6   6\n",
              "3  positive  29  30   2   31  32  33  34  ...   6   6   6   6   6   6   6   6\n",
              "4  positive   7  46  47   48  49  10  50  ...   6   6   6   6   6   6   6   6\n",
              "5  positive  58  59  38   60  50  38  15  ...   6   6   6   6   6   6   6   6\n",
              "6  negative  64   2  31   65   4  66  38  ...   6   6   6   6   6   6   6   6\n",
              "7  negative  70  71  72   10  71  73  74  ...   6   6   6   6   6   6   6   6\n",
              "8  negative  64   2  31   88  89  82  90  ...   6   6   6   6   6   6   6   6\n",
              "9  negative  51  98  99  100  15  10  15  ...   6   6   6   6   6   6   6   6\n",
              "\n",
              "[10 rows x 56 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c000abbf"
      },
      "source": [
        "### Word Embeddings"
      ],
      "id": "c000abbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "647caf36"
      },
      "source": [
        "Now that we can convert the original text (a sequence of strings) into a sequence of integer ids, can we directly feed that into the LSTM layer as we did for the shape classification problem?"
      ],
      "id": "647caf36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5903bc80"
      },
      "source": [
        "If we directly use those integer ids in the neural network, we are implicitly assuming that the word with id `1001` is closer to the word with id `1002` than it is to the word with id `10`. However, the way we constructed the mappings between word types and ids does not provide this property. \n",
        "Instead of directly using those word ids, for each word id, we maintain a different vector (usually termed an embedding), which can be stored in a matrix $E$ of size `vocab_size x embedding_size`. To get the word embedding for word id i, we can simply take the i-th row in the matrix $E_i$."
      ],
      "id": "5903bc80"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4461170b"
      },
      "source": [
        "In `Keras`, this embedding matrix is maintained in an `Embedding` layer.\n",
        "```\n",
        "Embedding(\n",
        "   input_dim,\n",
        "   output_dim,\n",
        "   embeddings_initializer=\"uniform\",\n",
        "   embeddings_regularizer=None,\n",
        "   activity_regularizer=None,\n",
        "   embeddings_constraint=None,\n",
        "   mask_zero=False,\n",
        "   input_length=None,\n",
        "   **kwargs\n",
        ")\n",
        "```\n",
        "Again, we don't need to use all arguments. The only two arguments that we need to understand are: `input_dim`, which is the size of the vocabulary `vocab_size`, and `output_dim`, which is the size of the word embeddings `embedding_size`."
      ],
      "id": "4461170b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.657593Z",
          "iopub.status.busy": "2021-08-05T17:09:24.656851Z",
          "iopub.status.idle": "2021-08-05T17:09:24.679242Z",
          "shell.execute_reply": "2021-08-05T17:09:24.679768Z"
        },
        "id": "521dc4e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f72c590-8723-42ac-cb2d-b75f4529ce76"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "model = Sequential()\n",
        "embedding_size = 32\n",
        "model.add(Embedding(vocab_size, embedding_size))\n",
        "# The model will take as input an integer matrix of size (num_samples, input_length).\n",
        "# The output_shape is (num_samples, input_length, embedding_size)\n",
        "#\n",
        "# take the first example as input\n",
        "inputs = tf.convert_to_tensor(df_train[features].iloc[:1])\n",
        "outputs = model(inputs)\n",
        "print (inputs.shape)\n",
        "print (outputs.shape)"
      ],
      "id": "521dc4e4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 55)\n",
            "(1, 55, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d867f83f"
      },
      "source": [
        "So now we have converted words to their word ids to their embeddings (token strings -> integer word ids -> vector word embeddings). (You might notice that the intermediate word id step is not necessary and we can directly map each word type to a word embedding: we used this intermediate word id step since tensors are easier to work with than strings, and we only need to do this conversion once for the dataset.)"
      ],
      "id": "d867f83f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae49d41d"
      },
      "source": [
        "👩🎓**Student question: By representing words as word embeddings, are we still making implicit assumptions that the 1001-st word is closer to the 1002-nd word than it is to the 10-th word?**"
      ],
      "id": "ae49d41d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.683941Z",
          "iopub.status.busy": "2021-08-05T17:09:24.683194Z",
          "iopub.status.idle": "2021-08-05T17:09:24.685463Z",
          "shell.execute_reply": "2021-08-05T17:09:24.686082Z"
        },
        "id": "08ce0cf1"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# No implicit assumptions "
      ],
      "id": "08ce0cf1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c40e0579"
      },
      "source": [
        "### Putting Everything Together"
      ],
      "id": "c40e0579"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7e8b9d1"
      },
      "source": [
        "Now we can put everything together and assemble a model for text classification: we have converted the token strings into word ids. The model first uses an embedding layer to convert those word ids into word embeddings, then the LSTM runs on top of those word embeddings, and we use a final projection layer to project to the output shape."
      ],
      "id": "e7e8b9d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15e147df"
      },
      "source": [
        "# Group Exercise B"
      ],
      "id": "15e147df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "227141f0"
      },
      "source": [
        "## Question 1"
      ],
      "id": "227141f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ea9888"
      },
      "source": [
        "Take another look at this model diagram. Can you explain what's happening in this diagram? What are the modules used? What are the inputs and outputs of each module?"
      ],
      "id": "a1ea9888"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2181ada"
      },
      "source": [
        "![image](https://www.researchgate.net/profile/Huy-Tien-Nguyen/publication/321259272/figure/fig2/AS:572716866433034@1513557749934/Illustration-of-our-LSTM-model-for-sentiment-classification-Each-word-is-transfered-to-a_W640.jpg)"
      ],
      "id": "b2181ada"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.692272Z",
          "iopub.status.busy": "2021-08-05T17:09:24.691451Z",
          "iopub.status.idle": "2021-08-05T17:09:24.693607Z",
          "shell.execute_reply": "2021-08-05T17:09:24.694108Z"
        },
        "lines_to_next_cell": 1,
        "id": "fd180be5"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# Long-short term memory networks and sequence of neural networks are being used to make predictions of the outcome. "
      ],
      "id": "fd180be5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c31df62e"
      },
      "source": [
        "## Question 2"
      ],
      "id": "c31df62e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2963af20"
      },
      "source": [
        "Finish the `TODO`s in the `create_rnn_model` function, train the network and report the test accuracy."
      ],
      "id": "2963af20"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:24.720074Z",
          "iopub.status.busy": "2021-08-05T17:09:24.719309Z",
          "iopub.status.idle": "2021-08-05T17:09:35.891845Z",
          "shell.execute_reply": "2021-08-05T17:09:35.892330Z"
        },
        "id": "dbdf4761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5dc353e-321b-4e1c-ab4e-f4cb723453fe"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "def create_rnn_model():\n",
        "    tf.random.set_seed(1234)\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # TODO: add embedding layer with embedding_size 32\n",
        "    pass\n",
        "    # TODO: add LSTM layer with hidden_size 32\n",
        "    pass\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_rnn_model,\n",
        "                        epochs=6,\n",
        "                        batch_size=150,\n",
        "                        verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features], y=df_train[\"class\"])\n",
        "# print summary\n",
        "print (model.model.summary())\n",
        "# predict on test set\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)\n",
        "pass\n",
        "\n",
        "def create_rnn_model():\n",
        "    tf.random.set_seed(1234)\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # TODO: add embedding layer\n",
        "    model.add(Embedding(vocab_size, 32)) # output size: length, 32\n",
        "    # TODO: add LSTM layer\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "    # Compile model\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_rnn_model,\n",
        "                        epochs=6,\n",
        "                        batch_size=150,\n",
        "                        verbose=1)\n",
        "# fit model\n",
        "model.fit(x=df_train[features], y=df_train[\"class\"])\n",
        "# print summary\n",
        "print (model.model.summary())\n",
        "# predict on test set\n",
        "df_test[\"predict\"] = model.predict(df_test[features])\n",
        "correct = (df_test[\"predict\"] == df_test[\"class\"])\n",
        "accuracy = correct.sum() / correct.size\n",
        "print (\"accuracy: \", accuracy)\n",
        "pass"
      ],
      "id": "dbdf4761",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 470.6189 - accuracy: 0.4892\n",
            "Epoch 2/6\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 318.7600 - accuracy: 0.5008\n",
            "Epoch 3/6\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 231.9498 - accuracy: 0.4877\n",
            "Epoch 4/6\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 154.8466 - accuracy: 0.4855\n",
            "Epoch 5/6\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 80.7914 - accuracy: 0.5069\n",
            "Epoch 6/6\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 38.9167 - accuracy: 0.4904\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 2)                 112       \n",
            "=================================================================\n",
            "Total params: 112\n",
            "Trainable params: 112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "accuracy:  0.49093904448105435\n",
            "Epoch 1/6\n",
            "47/47 [==============================] - 4s 45ms/step - loss: 0.6928 - accuracy: 0.5062\n",
            "Epoch 2/6\n",
            "47/47 [==============================] - 2s 45ms/step - loss: 0.6925 - accuracy: 0.5193\n",
            "Epoch 3/6\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 0.6804 - accuracy: 0.5501\n",
            "Epoch 4/6\n",
            "47/47 [==============================] - 2s 44ms/step - loss: 0.5050 - accuracy: 0.7672\n",
            "Epoch 5/6\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.3202 - accuracy: 0.8787\n",
            "Epoch 6/6\n",
            "47/47 [==============================] - 2s 47ms/step - loss: 0.2308 - accuracy: 0.9160\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 32)          154336    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 162,722\n",
            "Trainable params: 162,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "13/13 [==============================] - 1s 14ms/step\n",
            "accuracy:  0.8034047226798462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a849098b"
      },
      "source": [
        "## Question 3"
      ],
      "id": "a849098b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d492dbf8"
      },
      "source": [
        "Word embeddings might sound like a very abstract concept: we are associating each word with a vector, but what do these vectors mean? What properties do they possess? In this question, we will use the [Tensorflow Embedding Projector](https://projector.tensorflow.org/) to explore some pretrained word embeddings. (We can also take our trained model and visualize the embeddings from the embedding layer, but we usually need to train on very large datasets to see meaningful visualizations)"
      ],
      "id": "d492dbf8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cf88626"
      },
      "source": [
        "[Embedding Projector](https://projector.tensorflow.org/)"
      ],
      "id": "0cf88626"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4923fa4e"
      },
      "source": [
        "This visualization tool visualizes word embeddings in a 3-D space, but keep in mind that those embeddings are actually of much higher dimensionality (`embedding_size` is 200 in the default setting), and their neighbors are found in the original (200-D) space, not the 3-D space, which might lead to some seemingly nearby points not being shown as nearest neighbors."
      ],
      "id": "4923fa4e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea316b23"
      },
      "source": [
        "* Use the search tool in the right-side panel and search \"smith\". The point cloud in the middle pannel will show this word as well as its nearest neighbors. What did you observe about the neighbors of the word \"smith\"?"
      ],
      "id": "ea316b23"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:35.898192Z",
          "iopub.status.busy": "2021-08-05T17:09:35.897004Z",
          "iopub.status.idle": "2021-08-05T17:09:35.901038Z",
          "shell.execute_reply": "2021-08-05T17:09:35.900440Z"
        },
        "id": "b09d07ca"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# The neighbors of smith displayed the nearest points of words consisting of other names near the original space."
      ],
      "id": "b09d07ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc716b2d"
      },
      "source": [
        "* Let's try another word \"apple\" and find its nearest neighbors. What's your observation? Is \"apple\" considered a fruit or a company here? Do you consider this an issue for using word embeddings to represent text?"
      ],
      "id": "bc716b2d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:35.906719Z",
          "iopub.status.busy": "2021-08-05T17:09:35.905299Z",
          "iopub.status.idle": "2021-08-05T17:09:35.908623Z",
          "shell.execute_reply": "2021-08-05T17:09:35.909492Z"
        },
        "id": "36ef93c0"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# Apple is considered to be a company since there are word embeddings such as mac, intel, microsoft, windows and computers. "
      ],
      "id": "36ef93c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2adf111"
      },
      "source": [
        "## Question 4"
      ],
      "id": "f2adf111"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56a23611"
      },
      "source": [
        "Word embeddings are numeric representations of word types, hence they support algebraic operations. For example, we cannot compute `water + bird - air` in the string space, but we can compute `embedding_of_water + embedding_of_bird - embedding_of_air`. Then we can convert the resulting vector back to word by finding its nearest neighbors like we did in the previous question."
      ],
      "id": "56a23611"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ddd089a"
      },
      "source": [
        "Let's use this demo to perform word algebra."
      ],
      "id": "0ddd089a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a865f40"
      },
      "source": [
        "[Word Algebra](https://turbomaze.github.io/word2vecjson/)"
      ],
      "id": "4a865f40"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74573262"
      },
      "source": [
        "* Use the tool under section \"Word Algebra\" to find the nearest neighbors of `water + bird -air`. What do you get?"
      ],
      "id": "74573262"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:35.914254Z",
          "iopub.status.busy": "2021-08-05T17:09:35.913417Z",
          "iopub.status.idle": "2021-08-05T17:09:35.915986Z",
          "shell.execute_reply": "2021-08-05T17:09:35.916539Z"
        },
        "id": "e5649fa1"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# The neighbors were birds, water, fish, turtle, frog, animals, snake and owl. "
      ],
      "id": "e5649fa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453a0189"
      },
      "source": [
        "* Can you find some other interesting examples?"
      ],
      "id": "453a0189"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-05T17:09:35.923783Z",
          "iopub.status.busy": "2021-08-05T17:09:35.922890Z",
          "iopub.status.idle": "2021-08-05T17:09:35.925211Z",
          "shell.execute_reply": "2021-08-05T17:09:35.925770Z"
        },
        "id": "f7fd302a"
      },
      "source": [
        "#📝📝📝📝 FILLME\n",
        "# books + computers -magazine\n",
        "# The neighbors were library, machines, phones, toys, files and items"
      ],
      "id": "f7fd302a",
      "execution_count": null,
      "outputs": []
    }
  ]
}